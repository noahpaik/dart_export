# DART ì¬ë¬´ì œí‘œ & ì£¼ì„ ë°ì´í„° ìë™ ì¶”ì¶œ â€” ì¬ë¬´ëª¨ë¸ë§ íŒŒì´í”„ë¼ì¸

## 1. ê°œìš”

DART OpenAPIì—ì„œ **3ëŒ€ ì¬ë¬´ì œí‘œ(B/S, I/S, C/F)** ë¥¼ êµ¬ì¡°í™”ëœ APIë¡œ ì¶”ì¶œí•˜ê³ , ê³µì‹œ ì›ë¬¸ì—ì„œ **ì£¼ì„ ë°ì´í„°(ë¶€ë¬¸ë³„ ë§¤ì¶œ, íŒê´€ë¹„ ìƒì„¸, ê°ê°€ìƒê° ë‚´ì—­ ë“±)** ë¥¼ íŒŒì‹±í•˜ì—¬, ì¬ë¬´ëª¨ë¸ë§ìš© ì—‘ì…€ í…œí”Œë¦¿ì— ìë™ ì„¸íŒ…í•˜ëŠ” íŒŒì´í”„ë¼ì¸.

ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë‘ íŠ¸ë™ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤.

| íŠ¸ë™ | ë°ì´í„° | ì†ŒìŠ¤ | íŒŒì‹± ë‚œì´ë„ |
|------|--------|------|------------|
| **Track A** | B/S, I/S, C/F (í‘œì¤€ ì¬ë¬´ì œí‘œ) | DART êµ¬ì¡°í™” API (`fnlttSinglAcntAll`) | ë‚®ìŒ â€” JSON/êµ¬ì¡°í™” |
| **Track B** | ì£¼ì„ ìƒì„¸ (ë¶€ë¬¸ë³„, íŒê´€ë¹„ ë“±) | ê³µì‹œ ì›ë¬¸ HTML (`document.xml`) | ë†’ìŒ â€” HTML íŒŒì‹± + LLM ì •ê·œí™” |

Track AëŠ” DARTê°€ í‘œì¤€í™”ëœ ê³„ì • ì²´ê³„ë¡œ ì œê³µí•˜ë¯€ë¡œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ê³ , Track BëŠ” íšŒì‚¬ë§ˆë‹¤ ê³„ì •ëª…ì´ ë‹¬ë¼ LLM ê¸°ë°˜ ì •ê·œí™”ê°€ í•„ìš”í•˜ë‹¤.

---

## 2. ì „ì²´ ì•„í‚¤í…ì²˜

```
[DART OpenAPI]
     â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1       â”‚                    â”‚  Step 1       â”‚
â”‚  ê³µì‹œ íƒìƒ‰     â”‚  rcept_no í™•ë³´     â”‚  (ê³µìœ )        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                   â”‚
       â–¼                                   â–¼
 â•â•â• Track A â•â•â•                     â•â•â• Track B â•â•â•
 (3ëŒ€ ì¬ë¬´ì œí‘œ)                       (ì£¼ì„ ë°ì´í„°)
       â”‚                                   â”‚
       â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2A      â”‚                    â”‚  Step 2B      â”‚
â”‚  êµ¬ì¡°í™” API   â”‚                    â”‚  ì›ë¬¸ ë‹¤ìš´ë¡œë“œ  â”‚
â”‚  fnlttSingl   â”‚                    â”‚  document.xml  â”‚
â”‚  AcntAll      â”‚                    â”‚  â†’ HTML ì¶”ì¶œ   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                   â”‚
       â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3A      â”‚                    â”‚  Step 3B      â”‚
â”‚  DataFrame    â”‚                    â”‚  í…Œì´ë¸” íŒŒì‹±   â”‚
â”‚  ë³€í™˜ + ì •ë¦¬  â”‚                    â”‚  BS + read_htmlâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                   â”‚
       â”‚                                   â–¼
       â”‚                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                            â”‚  Step 4B      â”‚
       â”‚                            â”‚  LLM ê³„ì •ëª…   â”‚
       â”‚                            â”‚  ì •ê·œí™” + ìºì‹± â”‚
       â”‚                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                   â”‚
       â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: ì—‘ì…€ ì„¸íŒ…                            â”‚
â”‚  openpyxl â†’ ì¬ë¬´ëª¨ë¸ í…œí”Œë¦¿ì— ê°’ ì‚½ì…            â”‚
â”‚  B/S, I/S, C/F ì‹œíŠ¸ + ì£¼ì„ ìƒì„¸ ì‹œíŠ¸            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
dart_pipeline/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml              # API í‚¤, ëª¨ë¸ ì„¤ì •, ê²½ë¡œ
â”‚   â””â”€â”€ taxonomy.yaml              # í‘œì¤€ ê³„ì •ëª… ì²´ê³„ ì •ì˜
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dart_api.py                # DART OpenAPI í˜¸ì¶œ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ corp_code_db.py            # [ì‹ ê·œ] corp_code SQLite DB ê´€ë¦¬
â”‚   â”œâ”€â”€ financial_statements.py    # [Track A] B/S, I/S, C/F êµ¬ì¡°í™” ì¶”ì¶œ
â”‚   â”œâ”€â”€ document_classifier.py     # [Track B] ê³µì‹œ zip ë‚´ ì£¼ì„ íŒŒì¼ ì‹ë³„
â”‚   â”œâ”€â”€ html_parser.py             # [Track B] HTML ì£¼ì„ í…Œì´ë¸” íŒŒì‹±
â”‚   â”œâ”€â”€ account_normalizer.py      # [Track B] LLM ê¸°ë°˜ ê³„ì •ëª… ì •ê·œí™”
â”‚   â”œâ”€â”€ excel_writer.py            # ì—‘ì…€ í…œí”Œë¦¿ ì„¸íŒ… (ì „ì²´)
â”‚   â””â”€â”€ cache_db.py                # SQLite ìºì‹± ê´€ë¦¬
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ financial_model.xlsx       # ì¬ë¬´ëª¨ë¸ ì—‘ì…€ í…œí”Œë¦¿
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # ë‹¤ìš´ë¡œë“œëœ ì›ë³¸ zip/html
â”‚   â”œâ”€â”€ parsed/                    # íŒŒì‹±ëœ DataFrame (parquet)
â”‚   â”œâ”€â”€ corp_code.db               # [ì‹ ê·œ] ì „ì²´ ê¸°ì—… ê³ ìœ ë²ˆí˜¸ DB
â”‚   â””â”€â”€ cache.db                   # ê³„ì •ëª… ë§¤í•‘ ìºì‹œ
â”œâ”€â”€ main.py                        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì§„ì…ì 
â””â”€â”€ requirements.txt
```

---

## 4. ë‹¨ê³„ë³„ êµ¬í˜„

### Step 1: ê³µì‹œ íƒìƒ‰ â€” `dart_api.py`

DART OpenAPIë¡œ íŠ¹ì • íšŒì‚¬ì˜ ì‚¬ì—…ë³´ê³ ì„œ/ë°˜ê¸°ë³´ê³ ì„œ ëª©ë¡ì„ ì¡°íšŒí•˜ê³ , ê°€ì¥ ìµœê·¼ ê³µì‹œì˜ `rcept_no`ë¥¼ í™•ë³´í•œë‹¤.

**ì‚¬ìš© API**

| API | ì—”ë“œí¬ì¸íŠ¸ | ìš©ë„ |
|-----|-----------|------|
| ê³µì‹œëª©ë¡ | `/api/list.json` | rcept_no ì¡°íšŒ |
| ê³ ìœ ë²ˆí˜¸ | `/api/corpCode.xml` | íšŒì‚¬ëª… â†’ corp_code ë³€í™˜ |

**êµ¬í˜„ í¬ì¸íŠ¸**

```python
import requests

class DartAPI:
    BASE_URL = "https://opendart.fss.or.kr/api"

    def __init__(self, api_key: str):
        self.api_key = api_key

    def get_reports(self, corp_code: str, year: str, report_type: str = "11011") -> list[dict]:
        """
        ì‚¬ì—…ë³´ê³ ì„œ ëª©ë¡ ì¡°íšŒ
        report_type:
          11011 = ì‚¬ì—…ë³´ê³ ì„œ, 11012 = ë°˜ê¸°ë³´ê³ ì„œ
          11013 = 1ë¶„ê¸°ë³´ê³ ì„œ, 11014 = 3ë¶„ê¸°ë³´ê³ ì„œ
        """
        params = {
            "crtfc_key": self.api_key,
            "corp_code": corp_code,
            "bgn_de": f"{year}0101",
            "end_de": f"{year}1231",
            "pblntf_ty": "A",       # ì •ê¸°ê³µì‹œ
            "page_count": 100,
        }
        resp = requests.get(f"{self.BASE_URL}/list.json", params=params)
        data = resp.json()

        # report_typeì— í•´ë‹¹í•˜ëŠ” ê³µì‹œë§Œ í•„í„°ë§
        reports = []
        for item in data.get("list", []):
            if report_type in item.get("report_nm", ""):
                reports.append(item)
        return reports

    def get_corp_code(self, company_name: str) -> str | None:
        """íšŒì‚¬ëª…ìœ¼ë¡œ corp_code ì¡°íšŒ"""
        db = CorpCodeDB()
        if db.is_empty():
            print("ğŸ“¥ corp_code DB ì´ˆê¸°í™” ì¤‘ (ìµœì´ˆ 1íšŒ)...")
            db.build_from_dart(self.api_key)
        return db.search(company_name)
```

**corp_code ê´€ë¦¬ â€” `corp_code_db.py`**

`corpCode.xml` APIëŠ” ì „ì²´ ìƒì¥/ë¹„ìƒì¥ ê¸°ì—… ì•½ 100,000ê±´ì„ zipìœ¼ë¡œ ë°˜í™˜í•œë‹¤.
ë§¤ë²ˆ APIë¥¼ í˜¸ì¶œí•˜ë©´ ëŠë¦¬ë¯€ë¡œ, ìµœì´ˆ 1íšŒ SQLiteì— ì ì¬ í›„ ë¡œì»¬ ê²€ìƒ‰í•œë‹¤.

```python
import requests
import zipfile
import io
import sqlite3
import xml.etree.ElementTree as ET
from pathlib import Path

class CorpCodeDB:
    """
    DART ê³ ìœ ë²ˆí˜¸(corp_code) ë¡œì»¬ DB.
    
    corpCode.xml: ~100,000ê°œ ê¸°ì—…ì˜ corp_code, íšŒì‚¬ëª…, ì¢…ëª©ì½”ë“œ í¬í•¨.
    zip (ì•½ 2MB) â†’ XML íŒŒì‹± â†’ SQLite ì ì¬. ìµœì´ˆ 1íšŒë§Œ ìˆ˜í–‰.
    """

    def __init__(self, db_path: str = "data/corp_code.db"):
        self.db_path = db_path
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)
        self.conn = sqlite3.connect(db_path)
        self._ensure_table()

    def _ensure_table(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS corp (
                corp_code TEXT PRIMARY KEY,    -- DART ê³ ìœ ë²ˆí˜¸ (8ìë¦¬)
                corp_name TEXT NOT NULL,       -- íšŒì‚¬ëª…
                stock_code TEXT,               -- ì¢…ëª©ì½”ë“œ (6ìë¦¬, ë¹„ìƒì¥ì€ ë¹ˆê°’)
                modify_date TEXT,              -- ìµœì¢…ë³€ê²½ì¼
                is_listed INTEGER DEFAULT 0    -- ìƒì¥ ì—¬ë¶€ (í¸ì˜ìš©)
            )
        """)
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_corp_name ON corp(corp_name)"
        )
        self.conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_stock_code ON corp(stock_code)"
        )
        self.conn.commit()

    def is_empty(self) -> bool:
        row = self.conn.execute("SELECT COUNT(*) FROM corp").fetchone()
        return row[0] == 0

    def build_from_dart(self, api_key: str):
        """
        DART APIì—ì„œ corpCode.xml zipì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ DBì— ì ì¬.
        
        API: GET https://opendart.fss.or.kr/api/corpCode.xml
        ë°˜í™˜: zip íŒŒì¼ (ë‚´ë¶€ì— CORPCODE.xml)

        XML êµ¬ì¡°:
          <result>
            <list>
              <corp_code>00126380</corp_code>
              <corp_name>ì‚¼ì„±ì „ì</corp_name>
              <stock_code>005930</stock_code>
              <modify_date>20240301</modify_date>
            </list>
            ...ì•½ 100,000ê±´
          </result>
        """
        print("  â¬‡ï¸  corpCode.xml ë‹¤ìš´ë¡œë“œ ì¤‘...")
        resp = requests.get(
            "https://opendart.fss.or.kr/api/corpCode.xml",
            params={"crtfc_key": api_key},
        )

        if resp.status_code != 200:
            raise Exception(f"corpCode.xml ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {resp.status_code}")

        # zip í•´ì œ â†’ XML íŒŒì‹±
        with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:
            xml_filename = zf.namelist()[0]  # ë³´í†µ "CORPCODE.xml"
            xml_bytes = zf.read(xml_filename)

        print("  ğŸ” XML íŒŒì‹± ì¤‘...")
        root = ET.fromstring(xml_bytes)

        # DB ì ì¬ (batch insert)
        records = []
        for item in root.iter("list"):
            corp_code = item.findtext("corp_code", "").strip()
            corp_name = item.findtext("corp_name", "").strip()
            stock_code = item.findtext("stock_code", "").strip()
            modify_date = item.findtext("modify_date", "").strip()

            if not corp_code or not corp_name:
                continue

            # stock_codeê°€ 6ìë¦¬ ìˆ«ìë©´ ìƒì¥, ì•„ë‹ˆë©´ ë¹„ìƒì¥(" " ë˜ëŠ” ë¹ˆê°’)
            is_listed = 1 if stock_code and stock_code.strip() and len(stock_code.strip()) == 6 else 0
            records.append((corp_code, corp_name, stock_code.strip(), modify_date, is_listed))

        self.conn.executemany(
            "INSERT OR REPLACE INTO corp VALUES (?, ?, ?, ?, ?)",
            records,
        )
        self.conn.commit()
        print(f"  âœ… {len(records)}ê°œ ê¸°ì—… ì ì¬ ì™„ë£Œ (ìƒì¥: {sum(1 for r in records if r[4])}ê°œ)")

    def search(self, name: str) -> str | None:
        """
        íšŒì‚¬ëª…ìœ¼ë¡œ corp_code ê²€ìƒ‰.
        ì •í™• ì¼ì¹˜ â†’ ë¶€ë¶„ ì¼ì¹˜(ìƒì¥ ìš°ì„ ) ìˆœìœ¼ë¡œ ì‹œë„.
        """
        # 1ì°¨: ì •í™•íˆ ì¼ì¹˜
        row = self.conn.execute(
            "SELECT corp_code FROM corp WHERE corp_name = ?", (name,)
        ).fetchone()
        if row:
            return row[0]

        # 2ì°¨: ë¶€ë¶„ ì¼ì¹˜ (ìƒì¥ ê¸°ì—… ìš°ì„ , ì´ë¦„ ì§§ì€ ìˆœ = ë” ì •í™•í•œ ë§¤ì¹˜)
        rows = self.conn.execute(
            "SELECT corp_code, corp_name, is_listed FROM corp "
            "WHERE corp_name LIKE ? ORDER BY is_listed DESC, LENGTH(corp_name) ASC LIMIT 10",
            (f"%{name}%",),
        ).fetchall()

        if not rows:
            return None
        return rows[0][0]

    def search_by_stock_code(self, stock_code: str) -> str | None:
        """ì¢…ëª©ì½”ë“œ(6ìë¦¬)ë¡œ corp_code ê²€ìƒ‰. ì˜ˆ: '005930' â†’ '00126380'"""
        row = self.conn.execute(
            "SELECT corp_code FROM corp WHERE stock_code = ?", (stock_code,)
        ).fetchone()
        return row[0] if row else None

    def get_listed_corps(self) -> list[dict]:
        """ìƒì¥ ê¸°ì—…ë§Œ ì¡°íšŒ (~2,600ê°œ)"""
        rows = self.conn.execute(
            "SELECT corp_code, corp_name, stock_code FROM corp WHERE is_listed = 1"
        ).fetchall()
        return [
            {"corp_code": r[0], "corp_name": r[1], "stock_code": r[2]}
            for r in rows
        ]

    def refresh(self, api_key: str):
        """DB ì „ì²´ ê°±ì‹  (ì›” 1íšŒ ê¶Œì¥)"""
        self.conn.execute("DELETE FROM corp")
        self.build_from_dart(api_key)
```

**ì‚¬ìš© ì˜ˆì‹œ**

```python
db = CorpCodeDB()
db.build_from_dart("YOUR_API_KEY")  # ìµœì´ˆ 1íšŒ, ì•½ 5ì´ˆ

db.search("ì‚¼ì„±ì „ì")                  # â†’ "00126380"
db.search("SKí•˜ì´ë‹‰ìŠ¤")                # â†’ "00164779"
db.search("ì‚¼ì„±")                      # â†’ "00126380" (ìƒì¥+ìµœë‹¨ ì´ë¦„ ìš°ì„ )
db.search_by_stock_code("005930")      # â†’ "00126380"

# ì „ì²´ ìƒì¥ê¸°ì—… ëª©ë¡
listed = db.get_listed_corps()         # ~2,600ê°œ
```

> **ìš´ì˜ íŒ**
> - corpCode.xmlì€ DARTì—ì„œ ì¼ 1íšŒ ê°±ì‹  í•œë„ê°€ ìˆìœ¼ë¯€ë¡œ, ì›” 1íšŒ `refresh()` í˜¸ì¶œì´ë©´ ì¶©ë¶„
> - DB íŒŒì¼ í¬ê¸°: ì•½ 5~8MB (100,000ê±´)
> - `search()`ì˜ ë¶€ë¶„ ì¼ì¹˜ëŠ” "ì‚¼ì„±" ê²€ìƒ‰ ì‹œ "ì‚¼ì„±ì „ì", "ì‚¼ì„±SDI", "ì‚¼ì„±ë¬¼ì‚°" ë“±ì´ í›„ë³´ë¡œ ë‚˜ì˜¤ëŠ”ë°, ìƒì¥+ì§§ì€ì´ë¦„ ìš°ì„  ì •ë ¬ë¡œ ëŒ€ë¶€ë¶„ ì˜¬ë°”ë¥¸ ê²°ê³¼ë¥¼ ë°˜í™˜

---

### Step 2A: 3ëŒ€ ì¬ë¬´ì œí‘œ ì¶”ì¶œ (Track A) â€” `financial_statements.py`

DART OpenAPIì˜ êµ¬ì¡°í™”ëœ ì¬ë¬´ì œí‘œ APIë¥¼ ì‚¬ìš©í•œë‹¤. ì´ APIëŠ” **í‘œì¤€ ê³„ì • ì²´ê³„(K-IFRS taxonomy)** ë¡œ ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì œê³µí•˜ë¯€ë¡œ, HTML íŒŒì‹±ì´ë‚˜ LLM ì •ê·œí™”ê°€ í•„ìš” ì—†ë‹¤.

**ì‚¬ìš© API**

| API | ì—”ë“œí¬ì¸íŠ¸ | ìš©ë„ |
|-----|-----------|------|
| ë‹¨ì¼íšŒì‚¬ ì „ì²´ ì¬ë¬´ì œí‘œ | `/api/fnlttSinglAcntAll.json` | B/S, I/S, C/F ì „ í•­ëª© |
| ë‹¨ì¼íšŒì‚¬ ì£¼ìš” ê³„ì • | `/api/fnlttSinglAcnt.json` | ì£¼ìš” í•­ëª©ë§Œ (ê°„ëµ) |
| ë‹¤ì¤‘íšŒì‚¬ ì£¼ìš” ê³„ì • | `/api/fnlttMultiAcnt.json` | ë¹„êµ ë¶„ì„ìš© |

**í•µì‹¬: `fnlttSinglAcntAll` API ìŠ¤í™**

```
GET https://opendart.fss.or.kr/api/fnlttSinglAcntAll.json

íŒŒë¼ë¯¸í„°:
  crtfc_key   : API ì¸ì¦í‚¤
  corp_code   : ê³ ìœ ë²ˆí˜¸ (8ìë¦¬)
  bsns_year   : ì‚¬ì—…ì—°ë„ (ì˜ˆ: "2024")
  reprt_code  : ë³´ê³ ì„œ ì½”ë“œ
                 11011 = ì‚¬ì—…ë³´ê³ ì„œ (ì—°ê°„)
                 11012 = ë°˜ê¸°ë³´ê³ ì„œ
                 11013 = 1ë¶„ê¸°ë³´ê³ ì„œ
                 11014 = 3ë¶„ê¸°ë³´ê³ ì„œ
  fs_div      : CFS=ì—°ê²°, OFS=ë³„ë„
```

**ì‘ë‹µ êµ¬ì¡° (í•µì‹¬ í•„ë“œ)**

```json
{
  "status": "000",
  "list": [
    {
      "rcept_no": "20240315000123",
      "sj_div": "BS",              // BS=ì¬ë¬´ìƒíƒœí‘œ, IS=ì†ìµê³„ì‚°ì„œ,
                                    // CIS=í¬ê´„ì†ìµ, CF=í˜„ê¸ˆíë¦„, SCE=ìë³¸ë³€ë™
      "sj_nm": "ì¬ë¬´ìƒíƒœí‘œ",
      "account_id": "ifrs-full_CurrentAssets",
      "account_nm": "ìœ ë™ìì‚°",
      "account_detail": "-",
      "thstrm_nm": "ì œ 56 ê¸°",      // ë‹¹ê¸°
      "thstrm_amount": "218983382000000",
      "frmtrm_nm": "ì œ 55 ê¸°",      // ì „ê¸°
      "frmtrm_amount": "196972079000000",
      "bfefrmtrm_nm": "ì œ 54 ê¸°",   // ì „ì „ê¸°
      "bfefrmtrm_amount": "187817786000000",
      "ord": "1"                    // í‘œì‹œ ìˆœì„œ
    },
    ...
  ]
}
```

**êµ¬í˜„ í¬ì¸íŠ¸**

```python
import requests
import pandas as pd
from dataclasses import dataclass
from enum import Enum

class StatementType(Enum):
    BS = "BS"    # ì¬ë¬´ìƒíƒœí‘œ (Balance Sheet)
    IS = "IS"    # ì†ìµê³„ì‚°ì„œ (Income Statement)
    CIS = "CIS"  # í¬ê´„ì†ìµê³„ì‚°ì„œ (Comprehensive Income Statement)
    CF = "CF"    # í˜„ê¸ˆíë¦„í‘œ (Cash Flow Statement)
    SCE = "SCE"  # ìë³¸ë³€ë™í‘œ (Statement of Changes in Equity)

@dataclass
class FinancialStatement:
    statement_type: StatementType
    corp_code: str
    year: str
    fs_div: str              # CFS(ì—°ê²°) or OFS(ë³„ë„)
    df: pd.DataFrame         # ì •ë¦¬ëœ DataFrame
    raw_data: list[dict]     # ì›ë³¸ API ì‘ë‹µ

class FinancialStatementFetcher:
    BASE_URL = "https://opendart.fss.or.kr/api"

    def __init__(self, api_key: str):
        self.api_key = api_key

    def fetch_all_statements(
        self,
        corp_code: str,
        year: str,
        report_code: str = "11011",
        fs_div: str = "CFS",
    ) -> dict[StatementType, FinancialStatement]:
        """
        3ëŒ€ ì¬ë¬´ì œí‘œ + í¬ê´„ì†ìµ + ìë³¸ë³€ë™í‘œë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¨ë‹¤.
        API í˜¸ì¶œì€ 1íšŒë¡œ ì¶©ë¶„ â€” ì‘ë‹µì— ëª¨ë“  ì¬ë¬´ì œí‘œê°€ í¬í•¨ë¨.
        """
        params = {
            "crtfc_key": self.api_key,
            "corp_code": corp_code,
            "bsns_year": year,
            "reprt_code": report_code,
            "fs_div": fs_div,
        }

        resp = requests.get(f"{self.BASE_URL}/fnlttSinglAcntAll.json", params=params)
        data = resp.json()

        if data.get("status") != "000":
            raise Exception(f"DART API ì—ëŸ¬: {data.get('message')}")

        raw_list = data["list"]

        # sj_div(ì¬ë¬´ì œí‘œ êµ¬ë¶„)ë³„ë¡œ ë¶„ë¦¬
        statements = {}
        for st_type in StatementType:
            filtered = [row for row in raw_list if row["sj_div"] == st_type.value]
            if filtered:
                df = self._to_dataframe(filtered, st_type)
                statements[st_type] = FinancialStatement(
                    statement_type=st_type,
                    corp_code=corp_code,
                    year=year,
                    fs_div=fs_div,
                    df=df,
                    raw_data=filtered,
                )

        return statements

    def _to_dataframe(self, rows: list[dict], st_type: StatementType) -> pd.DataFrame:
        """API ì‘ë‹µì„ ê¹”ë”í•œ DataFrameìœ¼ë¡œ ë³€í™˜"""
        records = []
        for row in rows:
            record = {
                "ê³„ì •ID": row["account_id"],
                "ê³„ì •ëª…": row["account_nm"],
                "ê³„ì •ìƒì„¸": row.get("account_detail", ""),
                "ë‹¹ê¸°": self._parse_amount(row.get("thstrm_amount")),
                "ì „ê¸°": self._parse_amount(row.get("frmtrm_amount")),
                "ì „ì „ê¸°": self._parse_amount(row.get("bfefrmtrm_amount")),
                "í‘œì‹œìˆœì„œ": int(row.get("ord", 0)),
            }
            records.append(record)

        df = pd.DataFrame(records)
        df = df.sort_values("í‘œì‹œìˆœì„œ").reset_index(drop=True)

        # I/S, C/FëŠ” ëˆ„ì  ê¸ˆì•¡ê³¼ ë¶„ê¸° ê¸ˆì•¡ì´ ë¶„ë¦¬ë  ìˆ˜ ìˆìŒ
        # thstrm_add_amount(ë‹¹ê¸° ëˆ„ì ) í•„ë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if any("thstrm_add_amount" in row for row in rows):
            df["ë‹¹ê¸°ëˆ„ì "] = [
                self._parse_amount(row.get("thstrm_add_amount"))
                for row in rows
            ]

        return df

    def _parse_amount(self, value) -> float | None:
        """ê¸ˆì•¡ ë¬¸ìì—´ â†’ ìˆ«ì ë³€í™˜"""
        if value is None or value == "":
            return None
        try:
            cleaned = str(value).replace(",", "").strip()
            return float(cleaned)
        except (ValueError, TypeError):
            return None

    def fetch_multi_year(
        self,
        corp_code: str,
        years: list[str],
        report_code: str = "11011",
        fs_div: str = "CFS",
    ) -> dict[str, dict[StatementType, FinancialStatement]]:
        """
        ì—¬ëŸ¬ ì—°ë„ë¥¼ í•œ ë²ˆì— ìˆ˜ì§‘.
        ì‹œê³„ì—´ ì¬ë¬´ëª¨ë¸ì— í•„ìš”í•œ 3~5ë…„ì¹˜ ë°ì´í„°.
        """
        results = {}
        for year in years:
            try:
                statements = self.fetch_all_statements(corp_code, year, report_code, fs_div)
                results[year] = statements
                print(f"  âœ… {year}ë…„ ì¬ë¬´ì œí‘œ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"  âŒ {year}ë…„ ì‹¤íŒ¨: {e}")
        return results
```

**3ëŒ€ ì¬ë¬´ì œí‘œ â†’ ì‹œê³„ì—´ DataFrame ì¡°í•©**

APIëŠ” ì—°ë„ë³„ë¡œ ë‹¹ê¸°/ì „ê¸°/ì „ì „ê¸°ë¥¼ ì œê³µí•˜ë¯€ë¡œ, ì—¬ëŸ¬ í•´ë¥¼ ì¡°í•©í•˜ë©´ ì¤‘ë³µ ë°ì´í„°ê°€ ìƒê¸´ë‹¤. ì´ë¥¼ ì •ë¦¬í•˜ëŠ” ìœ í‹¸ë¦¬í‹°:

```python
def build_time_series(
    multi_year_data: dict[str, dict[StatementType, FinancialStatement]],
    target_type: StatementType,
) -> pd.DataFrame:
    """
    ì—¬ëŸ¬ ì—°ë„ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ì‹œê³„ì—´ DataFrameìœ¼ë¡œ í•©ì¹œë‹¤.

    ì˜ˆ: 2022~2024 ì‚¬ì—…ë³´ê³ ì„œë¥¼ ìˆ˜ì§‘í•˜ë©´
    â†’ 2020~2024ë…„ 5ê°œë…„ ì‹œê³„ì—´ì´ ì™„ì„±ë¨ (ì „ì „ê¸° í™œìš©)
    """
    all_frames = {}

    for year, statements in sorted(multi_year_data.items()):
        if target_type not in statements:
            continue
        df = statements[target_type].df

        # ë‹¹ê¸° ë°ì´í„°ë¥¼ í•´ë‹¹ ì—°ë„ë¡œ ë§¤í•‘
        year_df = df[["ê³„ì •ID", "ê³„ì •ëª…", "ë‹¹ê¸°"]].copy()
        year_df = year_df.rename(columns={"ë‹¹ê¸°": year})
        all_frames[year] = year_df

    if not all_frames:
        return pd.DataFrame()

    # ê³„ì •ID ê¸°ì¤€ìœ¼ë¡œ merge
    base = list(all_frames.values())[0][["ê³„ì •ID", "ê³„ì •ëª…"]]
    for year, year_df in all_frames.items():
        base = base.merge(
            year_df[["ê³„ì •ID", year]],
            on="ê³„ì •ID",
            how="outer",
        )

    return base
```

**DART API ê³„ì • ì²´ê³„ â€” ì¬ë¬´ëª¨ë¸ë§ìš© ì„¸ë¶€ ê³„ì •ID (K-IFRS Taxonomy)**

`fnlttSinglAcntAll` APIëŠ” íšŒì‚¬ê°€ ê³µì‹œí•œ **ëª¨ë“  ì„¸ë¶€ ê³„ì •**ì„ ë°˜í™˜í•œë‹¤. ì‚¼ì„±ì „ì ê¸°ì¤€ìœ¼ë¡œ ì•½ 210ê°œ í•­ëª©ì´ ë‚´ë ¤ì˜¤ë©°, ìœ ë™ìì‚° â†’ í˜„ê¸ˆ, ë§¤ì¶œì±„ê¶Œ, ì¬ê³ ìì‚° ë“± í•˜ìœ„ ê³„ì •ê¹Œì§€ í¬í•¨ëœë‹¤. ì•„ë˜ëŠ” ì¬ë¬´ëª¨ë¸ë§ì— í•„ìˆ˜ì ì¸ ì„¸ë¶€ ê³„ì • ëª©ë¡ì´ë‹¤.

**B/S â€” ì¬ë¬´ìƒíƒœí‘œ (sj_div: "BS")**

```
[ìì‚°]
â”œâ”€â”€ ìœ ë™ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentAssets
â”‚   â”œâ”€â”€ í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CashAndCashEquivalents
â”‚   â”œâ”€â”€ ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentFinancialAssets
â”‚   â”‚                           ë˜ëŠ” dart_ShortTermDepositsNotClassifiedAsCashEquivalents
â”‚   â”œâ”€â”€ ë‹¨ê¸°íˆ¬ìì¦ê¶Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentFinancialAssetsAtFairValueThroughProfitOrLoss
â”‚   â”œâ”€â”€ ë§¤ì¶œì±„ê¶Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_TradeAndOtherCurrentReceivables
â”‚   â”‚                           ë˜ëŠ” ifrs-full_TradeReceivables
â”‚   â”œâ”€â”€ ë¯¸ìˆ˜ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_OtherCurrentReceivables
â”‚   â”œâ”€â”€ ì„ ê¸‰ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentPrepaidExpenses
â”‚   â”‚                           ë˜ëŠ” ifrs-full_CurrentAdvances
â”‚   â”œâ”€â”€ ì¬ê³ ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Inventories
â”‚   â””â”€â”€ ê¸°íƒ€ìœ ë™ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€  ifrs-full_OtherCurrentAssets
â”‚
â”œâ”€â”€ ë¹„ìœ ë™ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_NoncurrentAssets
â”‚   â”œâ”€â”€ ì¥ê¸°ê¸ˆìœµìƒí’ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€  ifrs-full_NoncurrentFinancialAssets
â”‚   â”œâ”€â”€ ì¥ê¸°íˆ¬ìì¦ê¶Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€  ifrs-full_NoncurrentFinancialAssetsAtFairValue...
â”‚   â”œâ”€â”€ ê´€ê³„ê¸°ì—…íˆ¬ì â”€â”€â”€â”€â”€â”€â”€â”€â”€  ifrs-full_InvestmentsInAssociates
â”‚   â”‚                           ë˜ëŠ” ifrs-full_InvestmentsAccountedForUsingEquityMethod
â”‚   â”œâ”€â”€ ìœ í˜•ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_PropertyPlantAndEquipment
â”‚   â”‚   â”œâ”€â”€ í† ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Land
â”‚   â”‚   â”œâ”€â”€ ê±´ë¬¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Buildings
â”‚   â”‚   â”œâ”€â”€ êµ¬ì¶•ë¬¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_InvestmentProperty (ë˜ëŠ” dart_ í™•ì¥)
â”‚   â”‚   â”œâ”€â”€ ê¸°ê³„ì¥ì¹˜ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Machinery
â”‚   â”‚   â”œâ”€â”€ ê±´ì„¤ì¤‘ì¸ìì‚° â”€â”€â”€â”€ ifrs-full_ConstructionInProgress
â”‚   â”‚   â””â”€â”€ ê¸°íƒ€ìœ í˜•ìì‚° â”€â”€â”€â”€ ifrs-full_OtherPropertyPlantAndEquipment
â”‚   â”œâ”€â”€ ë¬´í˜•ìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_IntangibleAssetsOtherThanGoodwill
â”‚   â”œâ”€â”€ ì˜ì—…ê¶Œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Goodwill
â”‚   â”œâ”€â”€ ì‚¬ìš©ê¶Œìì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_RightOfUseAssets
â”‚   â”œâ”€â”€ ì´ì—°ë²•ì¸ì„¸ìì‚° â”€â”€â”€â”€â”€â”€ ifrs-full_DeferredTaxAssets
â”‚   â””â”€â”€ ê¸°íƒ€ë¹„ìœ ë™ìì‚° â”€â”€â”€â”€â”€â”€ ifrs-full_OtherNoncurrentAssets
â”‚
â””â”€â”€ ìì‚°ì´ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Assets

[ë¶€ì±„]
â”œâ”€â”€ ìœ ë™ë¶€ì±„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentLiabilities
â”‚   â”œâ”€â”€ ë§¤ì…ì±„ë¬´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_TradeAndOtherCurrentPayables
â”‚   â”‚                           ë˜ëŠ” ifrs-full_TradePayables
â”‚   â”œâ”€â”€ ë‹¨ê¸°ì°¨ì…ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_ShorttermBorrowings
â”‚   â”‚                           ë˜ëŠ” dart_ShortTermBorrowings
â”‚   â”œâ”€â”€ ìœ ë™ì„±ì¥ê¸°ë¶€ì±„ â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentPortionOfLongtermBorrowings
â”‚   â”œâ”€â”€ ë¯¸ì§€ê¸‰ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_OtherCurrentPayables
â”‚   â”œâ”€â”€ ì„ ìˆ˜ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentAdvancesReceived
â”‚   â”œâ”€â”€ ë¯¸ì§€ê¸‰ë¹„ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_AccruedExpenses (ë˜ëŠ” dart_ í™•ì¥)
â”‚   â”œâ”€â”€ ìœ ë™ë¦¬ìŠ¤ë¶€ì±„ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentLeaseLiabilities
â”‚   â”œâ”€â”€ ë¯¸ì§€ê¸‰ë²•ì¸ì„¸ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentTaxLiabilities
â”‚   â”œâ”€â”€ ì¶©ë‹¹ë¶€ì±„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CurrentProvisions
â”‚   â””â”€â”€ ê¸°íƒ€ìœ ë™ë¶€ì±„ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_OtherCurrentLiabilities
â”‚
â”œâ”€â”€ ë¹„ìœ ë™ë¶€ì±„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_NoncurrentLiabilities
â”‚   â”œâ”€â”€ ì‚¬ì±„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_BondsIssued (ë˜ëŠ” dart_BondsIssued)
â”‚   â”œâ”€â”€ ì¥ê¸°ì°¨ì…ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_LongtermBorrowings
â”‚   â”œâ”€â”€ ë¹„ìœ ë™ë¦¬ìŠ¤ë¶€ì±„ â”€â”€â”€â”€â”€â”€ ifrs-full_NoncurrentLeaseLiabilities
â”‚   â”œâ”€â”€ í‡´ì§ê¸‰ì—¬ë¶€ì±„(ìˆœí™•ì •ê¸‰ì—¬ë¶€ì±„) â”€â”€ ifrs-full_NetDefinedBenefitLiability
â”‚   â”œâ”€â”€ ì´ì—°ë²•ì¸ì„¸ë¶€ì±„ â”€â”€â”€â”€â”€â”€ ifrs-full_DeferredTaxLiabilities
â”‚   â”œâ”€â”€ ì¥ê¸°ì¶©ë‹¹ë¶€ì±„ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_NoncurrentProvisions
â”‚   â””â”€â”€ ê¸°íƒ€ë¹„ìœ ë™ë¶€ì±„ â”€â”€â”€â”€â”€â”€ ifrs-full_OtherNoncurrentLiabilities
â”‚
â””â”€â”€ ë¶€ì±„ì´ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Liabilities

[ìë³¸]
â”œâ”€â”€ ì§€ë°°ê¸°ì—…ì†Œìœ ì£¼ì§€ë¶„ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_EquityAttributableToOwnersOfParent
â”‚   â”œâ”€â”€ ìë³¸ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_IssuedCapital
â”‚   â”œâ”€â”€ ì£¼ì‹ë°œí–‰ì´ˆê³¼ê¸ˆ â”€â”€â”€â”€â”€â”€ ifrs-full_SharePremium
â”‚   â”œâ”€â”€ ì´ìµì‰ì—¬ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_RetainedEarnings
â”‚   â”œâ”€â”€ ê¸°íƒ€í¬ê´„ì†ìµëˆ„ê³„ì•¡ â”€â”€ ifrs-full_AccumulatedOtherComprehensiveIncome
â”‚   â”œâ”€â”€ ê¸°íƒ€ìë³¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_OtherEquityInterest (ë˜ëŠ” dart_ í™•ì¥)
â”‚   â””â”€â”€ ìê¸°ì£¼ì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_TreasuryShares
â”œâ”€â”€ ë¹„ì§€ë°°ì§€ë¶„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_NoncontrollingInterests
â””â”€â”€ ìë³¸ì´ê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Equity
```

**I/S â€” ì†ìµê³„ì‚°ì„œ (sj_div: "IS")**

```
ë§¤ì¶œì•¡(ìˆ˜ìµ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_Revenue
ë§¤ì¶œì›ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CostOfSales
ë§¤ì¶œì´ì´ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_GrossProfit
íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ dart_TotalSellingGeneralAdministrativeExpenses
â”‚   â”œâ”€â”€ ê¸‰ì—¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (ì£¼ì„ì—ì„œ ì¶”ì¶œ â€” Track B)
â”‚   â”œâ”€â”€ ê°ê°€ìƒê°ë¹„ â”€â”€â”€â”€â”€â”€â”€ (ì£¼ì„ì—ì„œ ì¶”ì¶œ â€” Track B)
â”‚   â”œâ”€â”€ ë¬´í˜•ìì‚°ìƒê°ë¹„ â”€â”€â”€â”€ (ì£¼ì„ì—ì„œ ì¶”ì¶œ â€” Track B)
â”‚   â”œâ”€â”€ ì§€ê¸‰ìˆ˜ìˆ˜ë£Œ â”€â”€â”€â”€â”€â”€â”€ (ì£¼ì„ì—ì„œ ì¶”ì¶œ â€” Track B)
â”‚   â”œâ”€â”€ ê´‘ê³ ì„ ì „ë¹„ â”€â”€â”€â”€â”€â”€â”€ (ì£¼ì„ì—ì„œ ì¶”ì¶œ â€” Track B)
â”‚   â””â”€â”€ ... ê¸°íƒ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (ì£¼ì„ì—ì„œ ì¶”ì¶œ â€” Track B)
ì˜ì—…ì´ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ dart_OperatingIncomeLoss
ê¸ˆìœµìˆ˜ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_FinanceIncome
â”‚   â”œâ”€â”€ ì´ììˆ˜ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_InterestRevenueCalculatedUsingEffectiveInterestMethod
â”‚   â””â”€â”€ ê¸°íƒ€ê¸ˆìœµìˆ˜ìµ â”€â”€â”€â”€â”€â”€ (íšŒì‚¬ë³„ í™•ì¥)
ê¸ˆìœµë¹„ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_FinanceCosts
â”‚   â”œâ”€â”€ ì´ìë¹„ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_InterestExpense
â”‚   â””â”€â”€ ê¸°íƒ€ê¸ˆìœµë¹„ìš© â”€â”€â”€â”€â”€â”€ (íšŒì‚¬ë³„ í™•ì¥)
ê¸°íƒ€ì˜ì—…ì™¸ìˆ˜ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_OtherIncome
ê¸°íƒ€ì˜ì—…ì™¸ë¹„ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_OtherExpense
ê´€ê³„ê¸°ì—…íˆ¬ìì†ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_ShareOfProfitLossOfAssociates...
ë²•ì¸ì„¸ë¹„ìš©ì°¨ê°ì „ìˆœì´ìµ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_ProfitLossBeforeTax
ë²•ì¸ì„¸ë¹„ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_IncomeTaxExpense
ë‹¹ê¸°ìˆœì´ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_ProfitLoss
â”‚   â”œâ”€â”€ ì§€ë°°ê¸°ì—…ì†Œìœ ì£¼ â”€â”€â”€â”€ ifrs-full_ProfitLossAttributableToOwnersOfParent
â”‚   â””â”€â”€ ë¹„ì§€ë°°ì§€ë¶„ â”€â”€â”€â”€â”€â”€ ifrs-full_ProfitLossAttributableToNoncontrollingInterests
ê¸°ë³¸ì£¼ë‹¹ì´ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_BasicEarningsLossPerShare
í¬ì„ì£¼ë‹¹ì´ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_DilutedEarningsLossPerShare
```

**C/F â€” í˜„ê¸ˆíë¦„í‘œ (sj_div: "CF")**

```
ì˜ì—…í™œë™í˜„ê¸ˆíë¦„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CashFlowsFromUsedInOperatingActivities
â”‚   â”œâ”€â”€ ë‹¹ê¸°ìˆœì´ìµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_ProfitLoss
â”‚   â”œâ”€â”€ ì¡°ì •í•­ëª© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (íšŒì‚¬ë³„ ì„¸ë¶€ êµ¬ì„±)
â”‚   â”‚   â”œâ”€â”€ ê°ê°€ìƒê°ë¹„ â”€â”€â”€â”€ ifrs-full_DepreciationAndAmortisationExpense
â”‚   â”‚   â”œâ”€â”€ ë¬´í˜•ìì‚°ìƒê°ë¹„  ifrs-full_AmortisationExpense
â”‚   â”‚   â”œâ”€â”€ í‡´ì§ê¸‰ì—¬ â”€â”€â”€â”€â”€â”€ (dart_ í™•ì¥)
â”‚   â”‚   â”œâ”€â”€ ë²•ì¸ì„¸ë¹„ìš© â”€â”€â”€â”€ ifrs-full_IncomeTaxExpense
â”‚   â”‚   â””â”€â”€ ê¸°íƒ€ì¡°ì • â”€â”€â”€â”€â”€â”€ (íšŒì‚¬ë³„)
â”‚   â””â”€â”€ ìš´ì „ìë³¸ë³€ë™ â”€â”€â”€â”€â”€â”€â”€ (íšŒì‚¬ë³„ ì„¸ë¶€ êµ¬ì„±)
â”‚       â”œâ”€â”€ ë§¤ì¶œì±„ê¶Œ ì¦ê° â”€â”€ (íšŒì‚¬ë³„)
â”‚       â”œâ”€â”€ ì¬ê³ ìì‚° ì¦ê° â”€â”€ (íšŒì‚¬ë³„)
â”‚       â”œâ”€â”€ ë§¤ì…ì±„ë¬´ ì¦ê° â”€â”€ (íšŒì‚¬ë³„)
â”‚       â””â”€â”€ ê¸°íƒ€ ì¦ê° â”€â”€â”€â”€â”€â”€ (íšŒì‚¬ë³„)
â”‚
íˆ¬ìí™œë™í˜„ê¸ˆíë¦„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CashFlowsFromUsedInInvestingActivities
â”‚   â”œâ”€â”€ ìœ í˜•ìì‚° ì·¨ë“ â”€â”€â”€â”€ ifrs-full_PurchaseOfPropertyPlantAndEquipment (CAPEX)
â”‚   â”œâ”€â”€ ìœ í˜•ìì‚° ì²˜ë¶„ â”€â”€â”€â”€ ifrs-full_ProceedsFromSalesOfPropertyPlantAndEquipment
â”‚   â”œâ”€â”€ ë¬´í˜•ìì‚° ì·¨ë“ â”€â”€â”€â”€ ifrs-full_PurchaseOfIntangibleAssets
â”‚   â”œâ”€â”€ ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ ìˆœì¦ê°  (íšŒì‚¬ë³„)
â”‚   â”œâ”€â”€ ì¥ê¸°ê¸ˆìœµìƒí’ˆ ìˆœì¦ê°  (íšŒì‚¬ë³„)
â”‚   â””â”€â”€ ê´€ê³„ê¸°ì—…íˆ¬ì â”€â”€â”€â”€â”€â”€ ifrs-full_PurchaseOfInvestments... (íšŒì‚¬ë³„)
â”‚
ì¬ë¬´í™œë™í˜„ê¸ˆíë¦„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CashFlowsFromUsedInFinancingActivities
â”‚   â”œâ”€â”€ ë‹¨ê¸°ì°¨ì…ê¸ˆ ìˆœì¦ê° â”€â”€ (íšŒì‚¬ë³„)
â”‚   â”œâ”€â”€ ì¥ê¸°ì°¨ì…ê¸ˆ ì°¨ì… â”€â”€â”€â”€ ifrs-full_ProceedsFromLongtermBorrowings
â”‚   â”œâ”€â”€ ì¥ê¸°ì°¨ì…ê¸ˆ ìƒí™˜ â”€â”€â”€â”€ ifrs-full_RepaymentsOfLongtermBorrowings
â”‚   â”œâ”€â”€ ì‚¬ì±„ ë°œí–‰ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_ProceedsFromIssuingBonds (íšŒì‚¬ë³„)
â”‚   â”œâ”€â”€ ì‚¬ì±„ ìƒí™˜ â”€â”€â”€â”€â”€â”€â”€ ifrs-full_RepaymentsOfBonds (íšŒì‚¬ë³„)
â”‚   â”œâ”€â”€ ìê¸°ì£¼ì‹ ì·¨ë“ â”€â”€â”€â”€ ifrs-full_PaymentsToAcquireOwnEquityInstruments
â”‚   â”œâ”€â”€ ë°°ë‹¹ê¸ˆ ì§€ê¸‰ â”€â”€â”€â”€â”€â”€ ifrs-full_DividendsPaid
â”‚   â””â”€â”€ ë¦¬ìŠ¤ë¶€ì±„ ìƒí™˜ â”€â”€â”€â”€ (IFRS 16, íšŒì‚¬ë³„)
â”‚
í™˜ìœ¨ë³€ë™íš¨ê³¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_EffectOfExchangeRateChangesOnCashAndCashEquivalents
í˜„ê¸ˆë°í˜„ê¸ˆì„±ìì‚° ìˆœì¦ê° â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_IncreaseDecreaseInCashAndCashEquivalents
ê¸°ì´ˆí˜„ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CashAndCashEquivalents (ê¸°ì´ˆ)
ê¸°ë§í˜„ê¸ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ifrs-full_CashAndCashEquivalents (ê¸°ë§)
```

> **ì¤‘ìš” ì°¸ê³ ì‚¬í•­**
> - `fnlttSinglAcntAll` APIëŠ” ìœ„ ì„¸ë¶€ ê³„ì •ì„ **ëª¨ë‘** ë°˜í™˜í•œë‹¤. ì‚¼ì„±ì „ì ê¸°ì¤€ BS ì•½ 50ê°œ, IS ì•½ 30ê°œ, CF ì•½ 50ê°œ, CIS+SCE í¬í•¨ ì´ ~210ê°œ í•­ëª©.
> - ë‹¤ë§Œ `account_id`ëŠ” íšŒì‚¬ë§ˆë‹¤ **ì™„ì „íˆ ë™ì¼í•˜ì§€ëŠ” ì•Šë‹¤**. K-IFRS í‘œì¤€ taxonomy(ifrs-full_)ëŠ” ë™ì¼í•˜ì§€ë§Œ, íšŒì‚¬ë³„ í™•ì¥ ê³„ì •(dart_ ë˜ëŠ” íšŒì‚¬ ìì²´ ê³„ì •)ì´ ì¶”ê°€ë  ìˆ˜ ìˆë‹¤.
> - ì˜ˆë¥¼ ë“¤ì–´, ì‚¼ì„±ì „ìëŠ” `dart_ShortTermDepositsNotClassifiedAsCashEquivalents`(ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ)ë¥¼ ì“°ì§€ë§Œ, ë‹¤ë¥¸ íšŒì‚¬ëŠ” `ifrs-full_CurrentFinancialAssets`ë¥¼ ì“¸ ìˆ˜ ìˆë‹¤.
> - **I/Sì˜ íŒê´€ë¹„ ìƒì„¸**ì™€ **C/Fì˜ ì¡°ì •í•­ëª©/ìš´ì „ìë³¸ ì„¸ë¶€**ëŠ” APIì—ì„œ í•©ê³„ë§Œ ì œê³µí•˜ê±°ë‚˜ íšŒì‚¬ë§ˆë‹¤ ì„¸ë¶€ ë¶„ë¥˜ê°€ ë‹¤ë¥¸ ê²½ìš°ê°€ ë§ì•„, ì´ ë¶€ë¶„ì€ **Track B(ì£¼ì„ HTML íŒŒì‹±)**ë¡œ ë³´ì™„í•´ì•¼ í•œë‹¤.

**Track A vs Track B ì„¸ë¶€ ì»¤ë²„ë¦¬ì§€ ë¹„êµ**

| í•­ëª© | Track A (API) | Track B (ì£¼ì„) | ë¹„ê³  |
|------|:---:|:---:|------|
| B/S ìœ ë™ìì‚° ì„¸ë¶€ (í˜„ê¸ˆ, AR, ì¬ê³  ë“±) | âœ… | â€” | APIì—ì„œ ëŒ€ë¶€ë¶„ ì„¸ë¶€ ì œê³µ |
| B/S ìœ í˜•ìì‚° ì„¸ë¶€ (í† ì§€, ê±´ë¬¼, ê¸°ê³„ ë“±) | âš ï¸ ì¼ë¶€ | âœ… | ìœ í˜•ìì‚° ì£¼ì„ì—ì„œ ìƒì„¸ ë‚´ì—­ |
| B/S ë¹„ìœ ë™ìì‚° ì„¸ë¶€ | âœ… | â€” | APIì—ì„œ ì œê³µ |
| B/S ë¶€ì±„ ì„¸ë¶€ (AP, ì°¨ì…ê¸ˆ ë“±) | âœ… | â€” | APIì—ì„œ ì œê³µ |
| I/S ë§¤ì¶œ~ì˜ì—…ì´ìµ | âœ… | â€” | API í‘œì¤€ |
| I/S íŒê´€ë¹„ ìƒì„¸ ë‚´ì—­ | âŒ í•©ê³„ë§Œ | âœ… í•„ìˆ˜ | í•µì‹¬ Track B ì˜ì—­ |
| I/S ê¸ˆìœµìˆ˜ìµ/ë¹„ìš© ìƒì„¸ | âš ï¸ ì¼ë¶€ | âœ… | ì´ììˆ˜ìµ/ë¹„ìš©ì€ API, ë‚˜ë¨¸ì§€ëŠ” ì£¼ì„ |
| C/F ì˜ì—…/íˆ¬ì/ì¬ë¬´ ëŒ€ë¶„ë¥˜ | âœ… | â€” | API í‘œì¤€ |
| C/F ì¡°ì •í•­ëª© ìƒì„¸ | âš ï¸ íšŒì‚¬ë³„ | âœ… | ê°ê°€ìƒê°ë¹„ ë“± ì£¼ì„ ë³´ì™„ |
| C/F CAPEX ì„¸ë¶€ | âœ… | âœ… | ìœ í˜•ìì‚°ì·¨ë“ì€ API, ì„¸ë¶€ëŠ” ì£¼ì„ |
| ë¶€ë¬¸ë³„ ë§¤ì¶œ | âŒ | âœ… í•„ìˆ˜ | ì˜¤ì§ ì£¼ì„ì—ì„œë§Œ |
| ìˆ˜ìµ ë¶„í•´ (ì œí’ˆ/ìš©ì—­ë³„) | âŒ | âœ… í•„ìˆ˜ | ì˜¤ì§ ì£¼ì„ì—ì„œë§Œ |

---

### Step 2B: ì›ë¬¸ ë‹¤ìš´ë¡œë“œ (Track B) â€” `dart_api.py`

`rcept_no`ë¡œ ê³µì‹œ ì›ë¬¸ zipì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , ì£¼ì„ ê´€ë ¨ HTML íŒŒì¼ì„ ì¶”ì¶œí•œë‹¤.

**ì‚¬ìš© API**

| API | ì—”ë“œí¬ì¸íŠ¸ | ë°˜í™˜ |
|-----|-----------|------|
| ì›ë³¸ë¬¸ì„œ | `/api/document.xml` | zip (HTML íŒŒì¼ë“¤) |

**êµ¬í˜„ í¬ì¸íŠ¸**

```python
import zipfile
import io
from pathlib import Path

class DartAPI:
    # ... (ì´ì–´ì„œ)

    def download_document(self, rcept_no: str, save_dir: str) -> list[Path]:
        """ê³µì‹œ ì›ë¬¸ HTML zip ë‹¤ìš´ë¡œë“œ ë° ì¶”ì¶œ"""
        params = {
            "crtfc_key": self.api_key,
            "rcept_no": rcept_no,
        }
        resp = requests.get(
            f"{self.BASE_URL}/document.xml",
            params=params,
            stream=True,
        )

        save_path = Path(save_dir) / rcept_no
        save_path.mkdir(parents=True, exist_ok=True)

        # zip í•´ì œ
        with zipfile.ZipFile(io.BytesIO(resp.content)) as zf:
            zf.extractall(save_path)

        # HTML íŒŒì¼ ëª©ë¡ ë°˜í™˜
        return list(save_path.glob("*.html")) + list(save_path.glob("*.htm"))
```

**ì£¼ì„ íŒŒì¼ ì‹ë³„ â€” `find_notes_files()`**

DART ê³µì‹œ zipì˜ íŒŒì¼ êµ¬ì¡°ëŠ” í‘œì¤€í™”ë˜ì–´ ìˆì§€ ì•Šë‹¤. íšŒì‚¬/ê³µì‹œë§ˆë‹¤ ë‹¤ë¥´ì§€ë§Œ, ì‹¤ì œë¡œ ê´€ì°°ë˜ëŠ” íŒ¨í„´ì€ í¬ê²Œ 3ê°€ì§€ì´ë‹¤.

```
íŒ¨í„´ A: ë‹¨ì¼ HTML (ì†Œí˜• ê¸°ì—…)
  â””â”€â”€ 0001.html          â† ì‚¬ì—…ë³´ê³ ì„œ ì „ì²´ê°€ í•˜ë‚˜ì˜ íŒŒì¼

íŒ¨í„´ B: ì„¹ì…˜ë³„ ë¶„ë¦¬ (ëŒ€í˜• ê¸°ì—…, ê°€ì¥ í”í•¨)
  â”œâ”€â”€ 0.html             â† í‘œì§€/ëª©ì°¨
  â”œâ”€â”€ 1.html             â† ì‚¬ì—…ì˜ ë‚´ìš©
  â”œâ”€â”€ 2.html             â† ì¬ë¬´ì œí‘œ ë³¸ë¬¸
  â”œâ”€â”€ 3.html             â† ì¬ë¬´ì œí‘œ ì£¼ì„ â˜…
  â”œâ”€â”€ 4.html             â† ê°ì‚¬ë³´ê³ ì„œ
  â””â”€â”€ ...

íŒ¨í„´ C: ì„œë¸Œë””ë ‰í† ë¦¬ í¬í•¨
  â”œâ”€â”€ main.html
  â”œâ”€â”€ images/
  â””â”€â”€ attached/
       â”œâ”€â”€ ì—°ê²°ì¬ë¬´ì œí‘œ.html
       â”œâ”€â”€ ì¬ë¬´ì œí‘œì£¼ì„.html  â˜…
       â””â”€â”€ ...
```

í•µì‹¬ ë¬¸ì œ: **ì£¼ì„ íŒŒì¼ì´ ì–´ëŠ ê²ƒì¸ì§€ íŒŒì¼ëª…ë§Œìœ¼ë¡œëŠ” ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš°ê°€ ë§ë‹¤.** `3.html` ê°™ì€ ìˆ«ì íŒŒì¼ëª…ì´ ëŒ€ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ **íŒŒì¼ ë‚´ìš© ê¸°ë°˜ ë¶„ë¥˜**ê°€ í•„ìˆ˜ì´ë‹¤.

```python
import re
from pathlib import Path
from bs4 import BeautifulSoup
from dataclasses import dataclass

@dataclass
class DartDocument:
    """ê³µì‹œ zipì—ì„œ ì‹ë³„ëœ ë¬¸ì„œ"""
    path: Path
    doc_type: str          # "notes", "financial_statements", "audit", "toc", "other"
    fs_type: str | None    # "consolidated", "separate", None
    confidence: float      # ì‹ë³„ ì‹ ë¢°ë„ (0~1)

class DocumentClassifier:
    """
    DART ê³µì‹œ zip ë‚´ HTML íŒŒì¼ì„ ë¶„ë¥˜í•˜ëŠ” í´ë˜ìŠ¤.
    
    ë¶„ë¥˜ ì „ëµ:
    1. HTML ë‚´ <title> íƒœê·¸ í™•ì¸
    2. ë³¸ë¬¸ ì²« 5,000ìì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
    3. ì£¼ì„ íŠ¹ìœ ì˜ êµ¬ì¡°ì  íŒ¨í„´ ê°ì§€ (ë²ˆí˜¸ ë§¤ê¸°ê¸°, í…Œì´ë¸” ë°€ë„)
    """

    # ì£¼ì„ íŒŒì¼ ì‹ë³„ í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜ í¬í•¨)
    NOTES_KEYWORDS = {
        # ì§ì ‘ì  í‘œí˜„ (ë†’ì€ ê°€ì¤‘ì¹˜)
        "ì¬ë¬´ì œí‘œì— ëŒ€í•œ ì£¼ì„": 1.0,
        "ì£¼ì„": 0.6,
        "ì¬ë¬´ì œí‘œì£¼ì„": 1.0,
        "Notes to": 0.8,
        # ì£¼ì„ì—ì„œë§Œ ë“±ì¥í•˜ëŠ” ë‚´ìš© (ì¤‘ê°„ ê°€ì¤‘ì¹˜)
        "ì¤‘ìš”í•œ íšŒê³„ì •ì±…": 0.7,
        "ìœ ì˜ì ì¸ íšŒê³„ì •ì±…": 0.7,
        "íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„": 0.5,    # ì£¼ì„ ìƒì„¸
        "ì˜ì—…ë¶€ë¬¸": 0.5,
        "ìˆ˜ìµì˜ ë¶„í•´": 0.5,
        "ê¸ˆìœµìƒí’ˆì˜ ë²”ì£¼": 0.4,
        "ë²•ì¸ì„¸ë¹„ìš©ì˜ êµ¬ì„±": 0.4,
    }

    # ì£¼ì„ì´ ì•„ë‹Œ ë¬¸ì„œì˜ í‚¤ì›Œë“œ (ì œì™¸ìš©)
    EXCLUDE_KEYWORDS = {
        "ê°ì‚¬ë³´ê³ ì„œ": "audit",
        "ë‚´ë¶€íšŒê³„ê´€ë¦¬": "audit",
        "ì‚¬ì—…ì˜ ë‚´ìš©": "business",
        "ì´ì‚¬ì˜ ê²½ì˜ì§„ë‹¨": "business",
        "ì£¼ì£¼ì´íšŒ": "toc",
        "ëª© ì°¨": "toc",
    }

    # ì¬ë¬´ì œí‘œ ë³¸ë¬¸ vs ì£¼ì„ êµ¬ë¶„ í‚¤ì›Œë“œ
    FS_BODY_KEYWORDS = [
        "ì¬ ë¬´ ìƒ íƒœ í‘œ",  # DART íŠ¹ìœ ì˜ ë„ì–´ì“°ê¸°
        "ì¬ë¬´ìƒíƒœí‘œ",
        "ì† ìµ ê³„ ì‚° ì„œ",
        "ì†ìµê³„ì‚°ì„œ",
        "í˜„ ê¸ˆ í ë¦„ í‘œ",
        "í˜„ê¸ˆíë¦„í‘œ",
    ]

    def classify_documents(self, html_files: list[Path]) -> list[DartDocument]:
        """ëª¨ë“  HTML íŒŒì¼ì„ ë¶„ë¥˜"""
        documents = []
        for f in html_files:
            doc = self._classify_single(f)
            documents.append(doc)
        return documents

    def find_notes_files(self, html_files: list[Path]) -> list[DartDocument]:
        """ì£¼ì„ íŒŒì¼ë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜ (ì‹ ë¢°ë„ìˆœ ì •ë ¬)"""
        all_docs = self.classify_documents(html_files)
        notes = [d for d in all_docs if d.doc_type == "notes"]
        notes.sort(key=lambda d: d.confidence, reverse=True)

        if not notes:
            # fallback: ì¬ë¬´ì œí‘œ íŒŒì¼ ì¤‘ í…Œì´ë¸”ì´ ê°€ì¥ ë§ì€ íŒŒì¼
            print("  âš ï¸ ì£¼ì„ íŒŒì¼ì„ í‚¤ì›Œë“œë¡œ ì‹ë³„ ëª»í•¨ â†’ í…Œì´ë¸” ë°€ë„ ê¸°ë°˜ fallback")
            notes = self._fallback_by_table_density(html_files)

        return notes

    def _classify_single(self, html_path: Path) -> DartDocument:
        """ë‹¨ì¼ HTML íŒŒì¼ ë¶„ë¥˜"""
        try:
            content = html_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            content = html_path.read_text(encoding="euc-kr", errors="ignore")

        # 1. <title> íƒœê·¸ í™•ì¸
        title = ""
        title_match = re.search(r"<title>(.*?)</title>", content, re.IGNORECASE | re.DOTALL)
        if title_match:
            title = title_match.group(1).strip()

        # 2. ë³¸ë¬¸ ì•ë¶€ë¶„ ì¶”ì¶œ (íŒŒì‹± ë¹„ìš© ì ˆì•½)
        head_text = self._extract_text(content[:10000])

        # 3. ì œì™¸ í‚¤ì›Œë“œ ì²´í¬ (ê°ì‚¬ë³´ê³ ì„œ, ëª©ì°¨ ë“±)
        for keyword, doc_type in self.EXCLUDE_KEYWORDS.items():
            if keyword in title or keyword in head_text[:500]:
                return DartDocument(
                    path=html_path, doc_type=doc_type,
                    fs_type=None, confidence=0.8,
                )

        # 4. ì£¼ì„ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        notes_score = 0.0
        search_text = title + " " + head_text
        for keyword, weight in self.NOTES_KEYWORDS.items():
            if keyword in search_text:
                notes_score += weight

        # 5. ì¬ë¬´ì œí‘œ ë³¸ë¬¸ vs ì£¼ì„ êµ¬ë¶„
        # ë³¸ë¬¸ì€ "ì¬ë¬´ìƒíƒœí‘œ" ë“±ì´ ì œëª©ìœ¼ë¡œ ë‚˜ì˜¤ê³  í…Œì´ë¸”ì´ ì ìŒ
        # ì£¼ì„ì€ "1. ì¼ë°˜ì‚¬í•­", "2. ì¤‘ìš”í•œ íšŒê³„ì •ì±…" ë“± ë²ˆí˜¸ íŒ¨í„´ + í…Œì´ë¸”ì´ ë§ìŒ
        is_fs_body = any(kw in head_text[:2000] for kw in self.FS_BODY_KEYWORDS)
        has_note_numbering = bool(re.search(
            r"(?:^|\n)\s*(?:\d+|[ê°€-í£])\.\s*(?:ì¼ë°˜ì‚¬í•­|íšŒê³„ì •ì±…|ì¤‘ìš”í•œ|ìœ ì˜ì |í˜„ê¸ˆ)",
            head_text[:5000],
        ))

        if is_fs_body and notes_score < 0.5:
            return DartDocument(
                path=html_path, doc_type="financial_statements",
                fs_type=self._detect_fs_type(head_text), confidence=0.7,
            )

        # 6. ìµœì¢… íŒì •
        if notes_score >= 0.5 or has_note_numbering:
            return DartDocument(
                path=html_path, doc_type="notes",
                fs_type=self._detect_fs_type(head_text),
                confidence=min(notes_score, 1.0),
            )

        return DartDocument(
            path=html_path, doc_type="other",
            fs_type=None, confidence=0.3,
        )

    def _detect_fs_type(self, text: str) -> str | None:
        """ì—°ê²° vs ë³„ë„ ì¬ë¬´ì œí‘œ êµ¬ë¶„"""
        head = text[:3000]
        if "ì—°ê²°" in head:
            return "consolidated"
        elif "ë³„ë„" in head or "ê°œë³„" in head:
            return "separate"
        return None

    def _extract_text(self, html: str) -> str:
        """HTMLì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ê°€ë³ê²Œ)"""
        text = re.sub(r"<[^>]+>", " ", html)
        text = re.sub(r"\s+", " ", text)
        return text.strip()

    def _fallback_by_table_density(self, html_files: list[Path]) -> list[DartDocument]:
        """
        í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ: í…Œì´ë¸” ìˆ˜ê°€ ê°€ì¥ ë§ì€ íŒŒì¼ = ì£¼ì„ì¼ í™•ë¥  ë†’ìŒ.
        
        ê·¼ê±°: ì£¼ì„ì€ íŒê´€ë¹„, ìœ í˜•ìì‚°, ë¶€ë¬¸ë³„ ì •ë³´ ë“± ìˆ˜ì‹­ ê°œ í…Œì´ë¸”ì„ í¬í•¨í•˜ì§€ë§Œ,
        ì¬ë¬´ì œí‘œ ë³¸ë¬¸ì€ B/S, I/S, C/F ë“± 3~5ê°œ í…Œì´ë¸”ë§Œ ìˆìŒ.
        """
        scored = []
        for f in html_files:
            try:
                content = f.read_text(encoding="utf-8", errors="ignore")
            except Exception:
                content = f.read_text(encoding="euc-kr", errors="ignore")

            table_count = content.lower().count("<table")
            scored.append((f, table_count))

        scored.sort(key=lambda x: x[1], reverse=True)

        # í…Œì´ë¸” ìˆ˜ ìƒìœ„ íŒŒì¼ì„ ì£¼ì„ìœ¼ë¡œ ì¶”ì •
        if scored and scored[0][1] > 10:
            return [DartDocument(
                path=scored[0][0], doc_type="notes",
                fs_type=None, confidence=0.4,
            )]

        return []
```

**ì‚¬ìš© ì˜ˆì‹œ (main.pyì—ì„œ)**

```python
classifier = DocumentClassifier()
notes_docs = classifier.find_notes_files(html_files)

for doc in notes_docs:
    print(f"  ğŸ“„ {doc.path.name} (type={doc.fs_type}, confidence={doc.confidence:.1f})")
```

> **ì‹¤ë¬´ì—ì„œ ë§Œë‚˜ëŠ” ì—£ì§€ ì¼€ì´ìŠ¤**
> - **íŒ¨í„´ A(ë‹¨ì¼ íŒŒì¼)**: ì‚¬ì—…ë³´ê³ ì„œ ì „ì²´ê°€ 1ê°œ HTML. ì´ ê²½ìš° ì£¼ì„ì€ ë¬¸ì„œ ì¤‘ê°„ì— ìˆìœ¼ë¯€ë¡œ, BeautifulSoupìœ¼ë¡œ "ì£¼ì„" ì„¹ì…˜ ì‹œì‘ì ì„ ì°¾ì•„ ì´í›„ í…Œì´ë¸”ë§Œ íŒŒì‹±í•´ì•¼ í•¨
> - **ì¸ì½”ë”© ë¬¸ì œ**: êµ¬í˜• ê³µì‹œëŠ” EUC-KR, ìµœê·¼ ê³µì‹œëŠ” UTF-8. ë‘ ì¸ì½”ë”©ì„ ëª¨ë‘ ì‹œë„í•˜ëŠ” fallback í•„ìˆ˜
> - **ì—°ê²° + ë³„ë„ ì£¼ì„ì´ ê°™ì€ íŒŒì¼**: `_detect_fs_type()`ìœ¼ë¡œ êµ¬ë¶„í•˜ë˜, ê¸°ë³¸ê°’ì€ ì—°ê²°ì¬ë¬´ì œí‘œ ìš°ì„ 

---

### Step 3B: í…Œì´ë¸” íŒŒì‹± (Track B) â€” `html_parser.py`

HTML ì£¼ì„ ë¬¸ì„œì—ì„œ í…Œì´ë¸”ì„ ì¶”ì¶œí•˜ê³ , ê° í…Œì´ë¸”ì´ ì–´ë–¤ ì£¼ì„ í•­ëª©ì¸ì§€ ë¼ë²¨ë§í•œë‹¤.

**í•µì‹¬ ë¡œì§**

```python
import pandas as pd
from bs4 import BeautifulSoup
from dataclasses import dataclass

@dataclass
class NoteTable:
    note_title: str          # ì£¼ì„ ì œëª© (ì˜ˆ: "íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„", "ë¶€ë¬¸ë³„ ì •ë³´")
    df: pd.DataFrame         # íŒŒì‹±ëœ í…Œì´ë¸”
    raw_html: str            # ì›ë³¸ HTML (ë””ë²„ê¹…ìš©)

class HTMLParser:

    # ì¶”ì¶œ ëŒ€ìƒ ì£¼ì„ í•­ëª© í‚¤ì›Œë“œ
    TARGET_NOTES = {
        "segment_revenue": ["ì˜ì—…ë¶€ë¬¸", "ë¶€ë¬¸ë³„", "ì‚¬ì—…ë¶€ë¬¸", "ë³´ê³ ë¶€ë¬¸"],
        "sga_detail":      ["íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„", "íŒê´€ë¹„"],
        "depreciation":    ["ìœ í˜•ìì‚°", "ê°ê°€ìƒê°"],
        "revenue_detail":  ["ìˆ˜ìµì˜ ë¶„í•´", "ë§¤ì¶œ êµ¬ì„±", "ì œí’ˆë³„ ë§¤ì¶œ"],
        "employee":        ["ì¢…ì—…ì›", "ì„ì§ì›", "ì¸ê±´ë¹„"],
        "rnd":             ["ì—°êµ¬ê°œë°œ", "ê²½ìƒì—°êµ¬"],
        "capex":           ["íˆ¬ìí™œë™", "ìœ í˜•ìì‚°ì˜ ì·¨ë“"],
    }

    def parse_notes(self, html_path: str) -> list[NoteTable]:
        """HTMLì—ì„œ ì£¼ì„ í…Œì´ë¸” ì¶”ì¶œ"""
        with open(html_path, "r", encoding="utf-8", errors="ignore") as f:
            soup = BeautifulSoup(f.read(), "html.parser")

        results = []
        tables = soup.find_all("table")

        for table in tables:
            # í…Œì´ë¸” ë°”ë¡œ ì•ì˜ í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì„ ì œëª© ì¶”ì¶œ
            title = self._find_table_title(table)
            note_type = self._classify_note(title)

            if note_type:
                try:
                    # pandasë¡œ í…Œì´ë¸” íŒŒì‹±
                    df = pd.read_html(str(table), header=0)[0]
                    df = self._clean_dataframe(df)

                    results.append(NoteTable(
                        note_title=title,
                        df=df,
                        raw_html=str(table),
                    ))
                except Exception as e:
                    print(f"í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨: {title} - {e}")

        return results

    def _find_table_title(self, table_tag) -> str:
        """í…Œì´ë¸” ì•ì˜ ì œëª©/ë¬¸ë§¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        # ì´ì „ í˜•ì œ íƒœê·¸ì—ì„œ í…ìŠ¤íŠ¸ ì°¾ê¸°
        for sibling in table_tag.previous_siblings:
            if hasattr(sibling, "get_text"):
                text = sibling.get_text(strip=True)
                if len(text) > 2 and len(text) < 100:
                    return text
        return ""

    def _classify_note(self, title: str) -> str | None:
        """ì£¼ì„ ì œëª©ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        for note_type, keywords in self.TARGET_NOTES.items():
            if any(kw in title for kw in keywords):
                return note_type
        return None

    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """DataFrame ì •ë¦¬: ë¹ˆ í–‰/ì—´ ì œê±°, ìˆ«ì ë³€í™˜"""
        # ì™„ì „íˆ ë¹ˆ í–‰/ì—´ ì œê±°
        df = df.dropna(how="all").dropna(axis=1, how="all")

        # ìˆ«ì ì»¬ëŸ¼ ë³€í™˜ (ì‰¼í‘œ, ê´„í˜¸ ì²˜ë¦¬)
        for col in df.columns[1:]:  # ì²« ë²ˆì§¸ ì—´ì€ ê³„ì •ëª…
            df[col] = (
                df[col]
                .astype(str)
                .str.replace(",", "", regex=False)
                .str.replace("(", "-", regex=False)
                .str.replace(")", "", regex=False)
                .str.strip()
            )
            df[col] = pd.to_numeric(df[col], errors="coerce")

        return df
```

**íŒŒì‹± ë‚œì´ë„ë³„ ëŒ€ì‘**

| ë‚œì´ë„ | ìƒí™© | ëŒ€ì‘ |
|--------|------|------|
| ì‰¬ì›€ | ê¹”ë”í•œ `<table>` íƒœê·¸ | `pd.read_html()` ì§ì ‘ ì‚¬ìš© |
| ë³´í†µ | ë³‘í•©ì…€, ë‹¤ì¤‘ í—¤ë” | BeautifulSoupìœ¼ë¡œ ì „ì²˜ë¦¬ í›„ íŒŒì‹± |
| ì–´ë ¤ì›€ | ì„œìˆ í˜• ì£¼ì„ ì•ˆì— ìˆ«ì ì‚°ì¬ | LLMì—ê²Œ ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì£¼ê³  í…Œì´ë¸” êµ¬ì„± ìš”ì²­ |

---

### Step 4B: ê³„ì •ëª… ì •ê·œí™” (Track B) â€” `account_normalizer.py`

íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬. íšŒì‚¬ë§ˆë‹¤ ë‹¤ë¥¸ ê³„ì •ëª…ì„ í‘œì¤€ ì²´ê³„ë¡œ ë§¤í•‘í•œë‹¤.

**í‘œì¤€ ê³„ì • ì²´ê³„ (taxonomy.yaml)**

```yaml
# config/taxonomy.yaml
sga_detail:
  standard_accounts:
    - ê¸‰ì—¬
    - í‡´ì§ê¸‰ì—¬
    - ë³µë¦¬í›„ìƒë¹„
    - ê°ê°€ìƒê°ë¹„
    - ë¬´í˜•ìì‚°ìƒê°ë¹„
    - ì§€ê¸‰ìˆ˜ìˆ˜ë£Œ
    - ê´‘ê³ ì„ ì „ë¹„
    - ìš´ë°˜ë¹„
    - ì„¸ê¸ˆê³¼ê³µê³¼
    - ëŒ€ì†ìƒê°ë¹„
    - ê¸°íƒ€íŒê´€ë¹„       # catch-all
  aliases:             # ìì£¼ ë‚˜ì˜¤ëŠ” ë³€í˜•ì„ ë¯¸ë¦¬ ë“±ë¡
    ê¸‰ì—¬ë°ìƒì—¬: ê¸‰ì—¬
    ì„ì§ì›ê¸‰ì—¬: ê¸‰ì—¬
    ì¢…ì—…ì›ê¸‰ì—¬: ê¸‰ì—¬
    í‡´ì§ê¸‰ì—¬ì¶©ë‹¹ë¶€ì±„ì „ì…ì•¡: í‡´ì§ê¸‰ì—¬
    ìˆ˜ì„ ìœ ì§€ë¹„: ê¸°íƒ€íŒê´€ë¹„

segment_revenue:
  standard_accounts:
    - ë¶€ë¬¸ëª…            # ë™ì ìœ¼ë¡œ ê²°ì •ë¨
  note: "ë¶€ë¬¸ë³„ ë§¤ì¶œì€ íšŒì‚¬ë§ˆë‹¤ ë¶€ë¬¸ëª…ì´ ë‹¤ë¥´ë¯€ë¡œ LLMì´ ë¶€ë¬¸ëª… ìì²´ë¥¼ ì¶”ì¶œ"

revenue_detail:
  standard_accounts:
    - ì œí’ˆë§¤ì¶œ
    - ìƒí’ˆë§¤ì¶œ
    - ìš©ì—­ë§¤ì¶œ
    - ê¸°íƒ€ë§¤ì¶œ
```

**ì •ê·œí™” ë¡œì§**

```python
import json
import yaml
import hashlib
from cache_db import CacheDB

class AccountNormalizer:

    def __init__(self, taxonomy_path: str, llm_client, cache_db: CacheDB):
        with open(taxonomy_path) as f:
            self.taxonomy = yaml.safe_load(f)
        self.llm = llm_client
        self.cache = cache_db

    def normalize(self, note_type: str, account_names: list[str], corp_code: str) -> dict:
        """
        ê³„ì •ëª… ë¦¬ìŠ¤íŠ¸ë¥¼ í‘œì¤€ ê³„ì •ëª…ìœ¼ë¡œ ë§¤í•‘

        Returns: {ì›ë³¸ê³„ì •ëª…: í‘œì¤€ê³„ì •ëª…} dict
        """
        # 1) ìºì‹œ í™•ì¸
        cache_key = self._make_cache_key(corp_code, note_type, account_names)
        cached = self.cache.get(cache_key)
        if cached:
            return cached

        # 2) ì‚¬ì „ ë§¤í•‘ (aliases)
        taxonomy_entry = self.taxonomy.get(note_type, {})
        aliases = taxonomy_entry.get("aliases", {})
        standard = taxonomy_entry.get("standard_accounts", [])

        mapping = {}
        unmapped = []

        for name in account_names:
            clean_name = name.strip()
            if clean_name in aliases:
                mapping[clean_name] = aliases[clean_name]
            elif clean_name in standard:
                mapping[clean_name] = clean_name
            else:
                unmapped.append(clean_name)

        # 3) ë¯¸ë§¤í•‘ í•­ëª©ì€ LLMìœ¼ë¡œ ì²˜ë¦¬
        if unmapped:
            llm_mapping = self._llm_normalize(note_type, unmapped, standard)
            mapping.update(llm_mapping)

        # 4) ìºì‹œ ì €ì¥
        self.cache.set(cache_key, mapping)

        return mapping

    def _llm_normalize(self, note_type: str, names: list[str], standard: list[str]) -> dict:
        """LLMì„ ì‚¬ìš©í•œ ê³„ì •ëª… ë§¤í•‘"""
        prompt = f"""í•œêµ­ ê¸°ì—… ì¬ë¬´ì œí‘œì˜ '{note_type}' ì£¼ì„ì—ì„œ ì¶”ì¶œí•œ ê³„ì •ëª…ì„ í‘œì¤€ ê³„ì •ëª…ì— ë§¤í•‘í•´ì¤˜.

## ê·œì¹™
- ì˜ë¯¸ê°€ ê°™ê±°ë‚˜ í¬í•¨ ê´€ê³„ë©´ ë§¤í•‘
- ì—¬ëŸ¬ í‘œì¤€ í•­ëª©ì— ê±¸ì¹˜ë©´ ê°€ì¥ ê°€ê¹Œìš´ í•˜ë‚˜ë§Œ ì„ íƒ
- ì–´ë””ì—ë„ ë§ì§€ ì•Šìœ¼ë©´ "ê¸°íƒ€"ë¡œ ë§¤í•‘
- í•©ê³„/ì†Œê³„ í–‰ì´ë©´ "SKIP"ìœ¼ë¡œ ë§¤í•‘

## ì…ë ¥
ì¶”ì¶œëœ ê³„ì •ëª…: {json.dumps(names, ensure_ascii=False)}
í‘œì¤€ ê³„ì •ëª…: {json.dumps(standard, ensure_ascii=False)}

## ì¶œë ¥ í˜•ì‹
JSONë§Œ ë°˜í™˜. ì„¤ëª… ì—†ì´.
{{"ì›ë³¸ê³„ì •ëª…": "í‘œì¤€ê³„ì •ëª…", ...}}"""

        response = self.llm.chat(prompt)
        return json.loads(response)

    def _make_cache_key(self, corp_code, note_type, names):
        raw = f"{corp_code}:{note_type}:{sorted(names)}"
        return hashlib.md5(raw.encode()).hexdigest()
```

**ìºì‹± ì „ëµ â€” `cache_db.py`**

```python
import sqlite3
import json

class CacheDB:
    def __init__(self, db_path: str = "data/cache.db"):
        self.conn = sqlite3.connect(db_path)
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS account_mapping (
                cache_key TEXT PRIMARY KEY,
                mapping TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

    def get(self, key: str) -> dict | None:
        row = self.conn.execute(
            "SELECT mapping FROM account_mapping WHERE cache_key = ?", (key,)
        ).fetchone()
        return json.loads(row[0]) if row else None

    def set(self, key: str, mapping: dict):
        self.conn.execute(
            "INSERT OR REPLACE INTO account_mapping (cache_key, mapping) VALUES (?, ?)",
            (key, json.dumps(mapping, ensure_ascii=False)),
        )
        self.conn.commit()
```

> ìºì‹±ì˜ íš¨ê³¼: ì‚¼ì„±ì „ìê°€ ë§¤ ë¶„ê¸° ê°™ì€ ê³„ì •ëª…ì„ ì‚¬ìš©í•œë‹¤ë©´, ìµœì´ˆ 1íšŒë§Œ LLM í˜¸ì¶œí•˜ê³  ì´í›„ëŠ” ì¦‰ì‹œ ë§¤í•‘ëœë‹¤. íšŒì‚¬ ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë„ LLM ë¹„ìš©ì´ ì„ í˜• ì¦ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤.

---

### Step 5: ì—‘ì…€ ì„¸íŒ… â€” `excel_writer.py`

Track A(3ëŒ€ ì¬ë¬´ì œí‘œ)ì™€ Track B(ì£¼ì„ ìƒì„¸)ë¥¼ ëª¨ë‘ ì—‘ì…€ í…œí”Œë¦¿ì— ì‚½ì…í•œë‹¤.

**êµ¬í˜„ í¬ì¸íŠ¸**

```python
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
import pandas as pd

class ExcelWriter:

    def __init__(self, template_path: str):
        self.wb = load_workbook(template_path)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Track A: 3ëŒ€ ì¬ë¬´ì œí‘œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def write_balance_sheet(self, df: pd.DataFrame, sheet_name: str = "BS"):
        """
        ì¬ë¬´ìƒíƒœí‘œ ê¸°ì…

        df ì»¬ëŸ¼: [ê³„ì •ID, ê³„ì •ëª…, 2020, 2021, 2022, 2023, 2024]
        """
        self._write_statement(df, sheet_name)

    def write_income_statement(self, df: pd.DataFrame, sheet_name: str = "IS"):
        """ì†ìµê³„ì‚°ì„œ ê¸°ì…"""
        self._write_statement(df, sheet_name)

    def write_cash_flow(self, df: pd.DataFrame, sheet_name: str = "CF"):
        """í˜„ê¸ˆíë¦„í‘œ ê¸°ì…"""
        self._write_statement(df, sheet_name)

    def _write_statement(self, df: pd.DataFrame, sheet_name: str):
        """
        3ëŒ€ ì¬ë¬´ì œí‘œ ê³µí†µ ê¸°ì… ë¡œì§

        ì „ëµ: í…œí”Œë¦¿ì˜ ê³„ì •IDì™€ APIì˜ ê³„ì •IDë¥¼ ë§¤ì¹­
        â†’ í‘œì¤€ taxonomyì´ë¯€ë¡œ íšŒì‚¬ê°€ ë‹¬ë¼ë„ ë™ì¼í•œ IDë¡œ ë§¤ì¹­ ê°€ëŠ¥
        â†’ ë‹¨, íšŒì‚¬ë³„ í™•ì¥ ê³„ì •(dart_ ë“±)ì€ aliasesë¡œ ë³´ì™„
        """
        ws = self.wb[sheet_name]

        # íšŒì‚¬ë³„ í™•ì¥ ê³„ì • â†’ í‘œì¤€ ê³„ì •ID ë§¤í•‘ (ê°™ì€ ì˜ë¯¸ì˜ ë‹¤ë¥¸ ID)
        ACCOUNT_ALIASES = {
            # ë‹¨ê¸°ê¸ˆìœµìƒí’ˆ: íšŒì‚¬ë§ˆë‹¤ ë‹¤ë¥¸ ID ì‚¬ìš©
            "dart_ShortTermDepositsNotClassifiedAsCashEquivalents": "ifrs-full_CurrentFinancialAssets",
            # ë‹¨ê¸°ì°¨ì…ê¸ˆ
            "dart_ShortTermBorrowings": "ifrs-full_ShorttermBorrowings",
            # ì‚¬ì±„
            "dart_BondsIssued": "ifrs-full_BondsIssued",
            # íŒê´€ë¹„ í•©ê³„
            "dart_TotalSellingGeneralAdministrativeExpenses": "dart_TotalSGA",
            # í•„ìš”ì‹œ ì¶”ê°€...
        }

        # í…œí”Œë¦¿ì—ì„œ ê³„ì •ID â†’ í–‰ë²ˆí˜¸ ë§¤í•‘ ì½ê¸°
        id_row_map = {}
        for row in ws.iter_rows(min_col=1, max_col=1):
            for cell in row:
                if cell.value and str(cell.value).startswith(("ifrs-", "dart_")):
                    id_row_map[str(cell.value).strip()] = cell.row

        col_map = self._read_col_map(ws, header_row=3)

        year_columns = [c for c in df.columns if c not in ("ê³„ì •ID", "ê³„ì •ëª…")]
        unmatched = []

        for _, row_data in df.iterrows():
            account_id = row_data["ê³„ì •ID"]
            target_row = None

            # 1ì°¨: ì§ì ‘ ë§¤ì¹­
            if account_id in id_row_map:
                target_row = id_row_map[account_id]
            # 2ì°¨: aliasesë¥¼ í†µí•œ ë§¤ì¹­
            elif account_id in ACCOUNT_ALIASES:
                alias = ACCOUNT_ALIASES[account_id]
                if alias in id_row_map:
                    target_row = id_row_map[alias]
            # 3ì°¨: ì—­ë°©í–¥ aliases (í…œí”Œë¦¿ì´ dart_, APIê°€ ifrs- ì¸ ê²½ìš°)
            else:
                for alias_from, alias_to in ACCOUNT_ALIASES.items():
                    if alias_to == account_id and alias_from in id_row_map:
                        target_row = id_row_map[alias_from]
                        break

            if target_row is None:
                unmatched.append((account_id, row_data["ê³„ì •ëª…"]))
                continue

            for year in year_columns:
                if year in col_map and pd.notna(row_data[year]):
                    ws.cell(row=target_row, column=col_map[year], value=row_data[year])

        if unmatched:
            print(f"  âš ï¸ {sheet_name}: ë¯¸ë§¤ì¹­ {len(unmatched)}ê°œ ê³„ì •")
            for aid, anm in unmatched[:5]:
                print(f"     - {anm} ({aid})")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Track B: ì£¼ì„ ìƒì„¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def write_sga_detail(self, data: dict, sheet_name: str = "íŒê´€ë¹„"):
        """
        íŒê´€ë¹„ ìƒì„¸ë¥¼ ì—‘ì…€ì— ê¸°ì…

        data í˜•íƒœ:
        {
            "ê¸‰ì—¬": {"2023": 150000, "2022": 140000},
            "ê°ê°€ìƒê°ë¹„": {"2023": 30000, "2022": 28000},
            ...
        }
        """
        ws = self.wb[sheet_name]

        # í…œí”Œë¦¿ì— ë¯¸ë¦¬ ì •ì˜ëœ í–‰ ë§¤í•‘ (í‘œì¤€ ê³„ì •ëª… â†’ í–‰ë²ˆí˜¸)
        row_map = self._read_row_map(ws, account_col="B")

        # í…œí”Œë¦¿ì— ë¯¸ë¦¬ ì •ì˜ëœ ì—´ ë§¤í•‘ (ì—°ë„ â†’ ì—´ë²ˆí˜¸)
        col_map = self._read_col_map(ws, header_row=3)

        for account_name, yearly_values in data.items():
            if account_name not in row_map:
                print(f"âš ï¸ í…œí”Œë¦¿ì— ì—†ëŠ” ê³„ì •: {account_name}")
                continue
            row = row_map[account_name]

            for year, value in yearly_values.items():
                if year not in col_map:
                    continue
                col = col_map[year]
                ws.cell(row=row, column=col, value=value)

    def write_segment_revenue(self, data: dict, sheet_name: str = "ë¶€ë¬¸ë³„ë§¤ì¶œ"):
        """ë¶€ë¬¸ë³„ ë§¤ì¶œì€ ë¶€ë¬¸ëª…ì´ ë™ì ì´ë¯€ë¡œ í–‰ì„ ë™ì ìœ¼ë¡œ ìƒì„±"""
        ws = self.wb[sheet_name]
        start_row = 5  # ë°ì´í„° ì‹œì‘ í–‰

        for i, (segment_name, yearly_values) in enumerate(data.items()):
            row = start_row + i
            ws.cell(row=row, column=2, value=segment_name)

            for year, value in yearly_values.items():
                col = self._year_to_col(ws, year, header_row=3)
                if col:
                    ws.cell(row=row, column=col, value=value)

    def save(self, output_path: str):
        self.wb.save(output_path)

    def _read_row_map(self, ws, account_col="B") -> dict:
        """ì‹œíŠ¸ì—ì„œ ê³„ì •ëª… â†’ í–‰ë²ˆí˜¸ ë§¤í•‘ ì½ê¸°"""
        row_map = {}
        for row in ws.iter_rows(min_col=2, max_col=2):
            for cell in row:
                if cell.value and isinstance(cell.value, str):
                    row_map[cell.value.strip()] = cell.row
        return row_map

    def _read_col_map(self, ws, header_row=3) -> dict:
        """ì‹œíŠ¸ì—ì„œ ì—°ë„ â†’ ì—´ë²ˆí˜¸ ë§¤í•‘ ì½ê¸°"""
        col_map = {}
        for cell in ws[header_row]:
            if cell.value:
                col_map[str(cell.value).strip()] = cell.column
        return col_map
```

---

### íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ â€” `main.py`

```python
from src.dart_api import DartAPI
from src.corp_code_db import CorpCodeDB
from src.financial_statements import FinancialStatementFetcher, StatementType, build_time_series
from src.document_classifier import DocumentClassifier
from src.html_parser import HTMLParser
from src.account_normalizer import AccountNormalizer
from src.excel_writer import ExcelWriter
from src.cache_db import CacheDB

def run_pipeline(
    company_name: str,
    corp_code: str | None = None,  # Noneì´ë©´ company_nameìœ¼ë¡œ ìë™ ê²€ìƒ‰
    years: list[str] = None,       # ì˜ˆ: ["2022", "2023", "2024"]
    api_key: str = "",
    llm_client = None,             # Noneì´ë©´ OpenClawLLM ìë™ ìƒì„±
    fs_div: str = "CFS",           # CFS=ì—°ê²°, OFS=ë³„ë„
):
    # ============================================
    # ì´ˆê¸°í™”
    # ============================================
    dart = DartAPI(api_key)
    fetcher = FinancialStatementFetcher(api_key)
    classifier = DocumentClassifier()
    parser = HTMLParser()
    cache = CacheDB()

    # LLM í´ë¼ì´ì–¸íŠ¸: OpenClaw ê²Œì´íŠ¸ì›¨ì´ ë˜ëŠ” ì§ì ‘ API
    if llm_client is None:
        llm_client = OpenClawLLM()  # localhost:4141 ê¸°ë³¸
    normalizer = AccountNormalizer("config/taxonomy.yaml", llm_client, cache)
    writer = ExcelWriter("templates/financial_model.xlsx")

    # corp_code ìë™ ì¡°íšŒ
    if corp_code is None:
        corp_code = dart.get_corp_code(company_name)
        if corp_code is None:
            raise ValueError(f"'{company_name}' ì— í•´ë‹¹í•˜ëŠ” corp_codeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        print(f"ğŸ¢ {company_name} â†’ corp_code: {corp_code}")

    if years is None:
        years = ["2022", "2023", "2024"]

    # ============================================
    # Track A: 3ëŒ€ ì¬ë¬´ì œí‘œ (êµ¬ì¡°í™” API)
    # ============================================
    print("â•" * 50)
    print("Track A: 3ëŒ€ ì¬ë¬´ì œí‘œ ìˆ˜ì§‘")
    print("â•" * 50)

    multi_year = fetcher.fetch_multi_year(corp_code, years, fs_div=fs_div)

    # B/S ì‹œê³„ì—´ ì¡°í•© â†’ ì—‘ì…€ ê¸°ì…
    bs_ts = build_time_series(multi_year, StatementType.BS)
    if not bs_ts.empty:
        writer.write_balance_sheet(bs_ts)
        print(f"  ğŸ“Š B/S: {len(bs_ts)}ê°œ ê³„ì •, {len(years)}ê°œë…„")

    # I/S ì‹œê³„ì—´ ì¡°í•© â†’ ì—‘ì…€ ê¸°ì…
    is_ts = build_time_series(multi_year, StatementType.IS)
    if not is_ts.empty:
        writer.write_income_statement(is_ts)
        print(f"  ğŸ“Š I/S: {len(is_ts)}ê°œ ê³„ì •, {len(years)}ê°œë…„")

    # C/F ì‹œê³„ì—´ ì¡°í•© â†’ ì—‘ì…€ ê¸°ì…
    cf_ts = build_time_series(multi_year, StatementType.CF)
    if not cf_ts.empty:
        writer.write_cash_flow(cf_ts)
        print(f"  ğŸ“Š C/F: {len(cf_ts)}ê°œ ê³„ì •, {len(years)}ê°œë…„")

    # ============================================
    # Track B: ì£¼ì„ ë°ì´í„° (HTML íŒŒì‹±)
    # ============================================
    print("\n" + "â•" * 50)
    print("Track B: ì£¼ì„ ë°ì´í„° ì¶”ì¶œ")
    print("â•" * 50)

    # ê°€ì¥ ìµœê·¼ ì—°ë„ì˜ ì‚¬ì—…ë³´ê³ ì„œì—ì„œ ì£¼ì„ ì¶”ì¶œ
    latest_year = max(years)
    reports = dart.get_reports(corp_code, latest_year)
    rcept_no = reports[0]["rcept_no"]
    print(f"  ğŸ“‹ ê³µì‹œë²ˆí˜¸: {rcept_no}")

    # ì›ë¬¸ ë‹¤ìš´ë¡œë“œ
    html_files = dart.download_document(rcept_no, f"data/raw/{company_name}")

    # ì£¼ì„ íŒŒì¼ ì‹ë³„ (DocumentClassifier ì‚¬ìš©)
    notes_docs = classifier.find_notes_files(html_files)
    print(f"  ğŸ“„ ì£¼ì„ íŒŒì¼ {len(notes_docs)}ê°œ ë°œê²¬")
    for doc in notes_docs:
        print(f"     - {doc.path.name} (fs={doc.fs_type}, conf={doc.confidence:.1f})")

    # ì—°ê²°ì¬ë¬´ì œí‘œ ì£¼ì„ ìš°ì„  (ì—†ìœ¼ë©´ ì „ì²´)
    consolidated_notes = [d for d in notes_docs if d.fs_type == "consolidated"]
    target_notes = consolidated_notes if consolidated_notes else notes_docs

    # í…Œì´ë¸” íŒŒì‹±
    all_tables = []
    for doc in target_notes:
        tables = parser.parse_notes(str(doc.path))
        all_tables.extend(tables)
    print(f"  ğŸ“Š ì£¼ì„ í…Œì´ë¸” {len(all_tables)}ê°œ ì¶”ì¶œ")

    # ì •ê·œí™” + ì—‘ì…€ ì„¸íŒ…
    for table in all_tables:
        account_names = table.df.iloc[:, 0].tolist()
        mapping = normalizer.normalize(
            note_type=table.note_title,
            account_names=account_names,
            corp_code=corp_code,
        )
        table.df["í‘œì¤€ê³„ì •"] = table.df.iloc[:, 0].map(mapping)

        # note_typeì— ë”°ë¼ ì ì ˆí•œ writer ë©”ì„œë“œ í˜¸ì¶œ
        if "sga" in table.note_title:
            writer.write_sga_detail(table.df)
        elif "segment" in table.note_title:
            writer.write_segment_revenue(table.df)
        # ... ê¸°íƒ€ ì£¼ì„ í•­ëª©

    # ============================================
    # ì €ì¥
    # ============================================
    output_path = f"data/{company_name}_{latest_year}_model.xlsx"
    writer.save(output_path)
    print(f"\nâœ… ì™„ë£Œ: {output_path}")


if __name__ == "__main__":
    # ë°©ë²• 1: OpenClaw ê²Œì´íŠ¸ì›¨ì´ ê²½ìœ  (ì¶”ì²œ)
    run_pipeline(
        company_name="ì‚¼ì„±ì „ì",
        years=["2022", "2023", "2024"],
        api_key="YOUR_DART_API_KEY",
        # llm_client ìƒëµ â†’ OpenClawLLM ìë™ ìƒì„±
    )

    # ë°©ë²• 2: ì§ì ‘ API í˜¸ì¶œ (OpenClaw ì—†ì„ ë•Œ)
    # from src.llm_client import DirectLLM
    # run_pipeline(
    #     company_name="SKí•˜ì´ë‹‰ìŠ¤",
    #     years=["2022", "2023", "2024"],
    #     api_key="YOUR_DART_API_KEY",
    #     llm_client=DirectLLM(provider="gemini", model="gemini-2.5-flash-lite"),
    # )
```

---

## 5. LLM ì—°ë™: OpenClaw API ë¼ìš°íŒ…

> ë¡œì»¬ LLM(Qwen2.5 14B) ëŒ€ì‹  OpenClawì— ì—°ë™ëœ í´ë¼ìš°ë“œ ëª¨ë¸ì„ ì‚¬ìš©í•œë‹¤.
> Track C(XBRL) ë„ì…ìœ¼ë¡œ LLM í•„ìš” ì¼€ì´ìŠ¤ê°€ ëŒ€í­ ì¤„ì—ˆìœ¼ë¯€ë¡œ, ë¹„ìš© ë¶€ë‹´ì´ ë‚®ë‹¤.

### 5-1. ëª¨ë¸ë³„ ì—­í•  ë°°ë¶„

| ì‘ì—… | ë‚œì´ë„ | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
|------|:---:|------|------|
| ê³„ì •ëª… ë§¤í•‘ (aliases miss) | ë‚®ìŒ | **GPT-5.2*** | ë¬´ë£Œ, ë‹¨ìˆœ ë§¤í•‘ì— ì¶©ë¶„ |
| entity_ í™•ì¥ ê³„ì • í•´ì„ | ì¤‘ê°„ | **GPT-5.2** (Codex) | 400K ì»¨í…ìŠ¤íŠ¸, ì¶”ë¡  ê°•ë ¥ |
| TextBlock ì„œìˆ í˜• íŒŒì‹± | ë†’ìŒ | **GPT-5.2** (Codex) | ê¸´ ë¬¸ì„œ + ìˆ«ì ì¶”ì¶œ ì •í™•ë„ |
| ë³µí•© í…Œì´ë¸” êµ¬ì¡° í•´ì„ | ë†’ìŒ | **GPT-5.2** (Codex) | ë³µì¡ ì¶”ë¡ , Opusê¸‰ ì„±ëŠ¥ |
| ë²Œí¬ ì²˜ë¦¬ (ìˆ˜ì‹­ ê°œ íšŒì‚¬) | â€” | **GPT-5.2*** | RPD 1,000, ì†ë„ ìµœê³  |

### 5-2. OpenClaw Gateway í™œìš© LLM í´ë¼ì´ì–¸íŠ¸

OpenClawì˜ ê²Œì´íŠ¸ì›¨ì´ëŠ” `http://localhost:PORT`ì—ì„œ OpenAI í˜¸í™˜ APIë¥¼ ì œê³µí•œë‹¤.
ë³„ë„ SDK ì—†ì´ í‘œì¤€ `openai` íŒ¨í‚¤ì§€ë¡œ ì ‘ê·¼ ê°€ëŠ¥.

```python
import json
import os
from openai import OpenAI

class OpenClawLLM:
    """
    OpenClaw ê²Œì´íŠ¸ì›¨ì´ë¥¼ í†µí•œ LLM í´ë¼ì´ì–¸íŠ¸.
    
    OpenClawì´ Google Antigravity, GitHub Copilot, Groq ë“±ì˜
    ì¸ì¦/ë¼ìš°íŒ…ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ, íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” ëª¨ë¸ IDë§Œ ì§€ì •í•˜ë©´ ëœë‹¤.
    """

    # ì‘ì—…ë³„ ê¸°ë³¸ ëª¨ë¸ ë¼ìš°íŒ…
    MODEL_ROUTES = {
        "account_mapping":    "openai-codex/gpt-5.2",             # ë¬´ë£Œ, ë‹¨ìˆœ ë§¤í•‘
        "entity_interpret":   "openai-codex/gpt-5.2",             # 400K ì»¨í…ìŠ¤íŠ¸, íšŒê³„ ì¶”ë¡ 
        "textblock_parse":    "openai-codex/gpt-5.2",             # ê¸´ í…ìŠ¤íŠ¸ íŒŒì‹± + ì¶”ë¡ 
        "complex_table":      "openai-codex/gpt-5.2",             # ë³µí•© í…Œì´ë¸” êµ¬ì¡° í•´ì„
        "bulk_normalize":     "openai-codex/gpt-5.2",             # ì†ë„ ìš°ì„ 
    }

    def __init__(
        self,
        gateway_url: str = "http://localhost:4141",  # OpenClaw ê¸°ë³¸ í¬íŠ¸
        default_model: str = "google/gemini-2.5-flash-lite",
    ):
        self.client = OpenAI(
            base_url=f"{gateway_url}/v1",
            api_key="openclaw",  # ê²Œì´íŠ¸ì›¨ì´ê°€ ì¸ì¦ ì²˜ë¦¬
        )
        self.default_model = default_model

    def chat(
        self,
        prompt: str,
        task_type: str | None = None,
        model: str | None = None,
        temperature: float = 0.1,
        max_tokens: int = 4096,
    ) -> str:
        """
        LLM í˜¸ì¶œ. task_typeìœ¼ë¡œ ìë™ ë¼ìš°íŒ…í•˜ê±°ë‚˜ model ì§ì ‘ ì§€ì •.

        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            task_type: "account_mapping" | "entity_interpret" | "textblock_parse" | ...
            model: ì§ì ‘ ì§€ì • ì‹œ task_type ë¬´ì‹œ
            temperature: ê³„ì • ë§¤í•‘ì€ 0.0~0.1 ê¶Œì¥
            max_tokens: ì‘ë‹µ ìµœëŒ€ í† í°
        """
        selected_model = (
            model
            or self.MODEL_ROUTES.get(task_type, self.default_model)
        )

        response = self.client.chat.completions.create(
            model=selected_model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens,
        )

        return response.choices[0].message.content

    def chat_json(
        self,
        prompt: str,
        task_type: str | None = None,
        **kwargs,
    ) -> dict:
        """JSON ì‘ë‹µì„ íŒŒì‹±í•´ì„œ ë°˜í™˜"""
        raw = self.chat(prompt, task_type=task_type, **kwargs)

        # ```json ... ``` ë¸”ë¡ ì œê±°
        clean = raw.strip()
        if clean.startswith("```"):
            clean = clean.split("\n", 1)[1]  # ì²« ì¤„ ì œê±°
            clean = clean.rsplit("```", 1)[0]  # ë§ˆì§€ë§‰ ``` ì œê±°

        return json.loads(clean)
```

### 5-3. ì§ì ‘ API í˜¸ì¶œ ë°©ì‹ (OpenClaw ì—†ì´ë„ ê°€ëŠ¥)

OpenClaw ê²Œì´íŠ¸ì›¨ì´ ì—†ì´ ê° í”„ë¡œë°”ì´ë” APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ê²½ìš°:

```python
class DirectLLM:
    """
    OpenClaw ì—†ì´ API ì§ì ‘ í˜¸ì¶œ.
    í”„ë¡œë°”ì´ë”ë³„ API í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬.
    """

    PROVIDERS = {
        "gemini": {
            "base_url": "https://generativelanguage.googleapis.com/v1beta",
            "env_key": "GOOGLE_API_KEY",
        },
        "groq": {
            "base_url": "https://api.groq.com/openai/v1",
            "env_key": "GROQ_API_KEY",
        },
        "deepseek": {
            "base_url": "https://api.deepseek.com",
            "env_key": "DEEPSEEK_API_KEY",
        },
    }

    def __init__(self, provider: str = "gemini", model: str = "gemini-2.5-flash-lite"):
        config = self.PROVIDERS[provider]
        self.client = OpenAI(
            base_url=config["base_url"],
            api_key=os.environ[config["env_key"]],
        )
        self.model = model

    def chat(self, prompt: str, **kwargs) -> str:
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            **kwargs,
        )
        return response.choices[0].message.content
```

### 5-4. ë¹„ìš© ìµœì í™” ì „ëµ

Track C(XBRL) ë„ì… í›„ LLM í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°:

| ë‹¨ê³„ | LLM í•„ìš”? | ì´ìœ  |
|------|:---------:|------|
| B/S, I/S, C/F ê°’ ì¶”ì¶œ | âŒ | Track A(API) |
| ì£¼ì„ êµ¬ì¡° íŒŒì•… | âŒ | Track C â€” pre.xml role ë§¤í•‘ |
| ê³„ì •ëª… â†’ í•œêµ­ì–´ ë¼ë²¨ | âŒ | Track C â€” lab-ko.xml |
| íŒê´€ë¹„ ìƒì„¸ ë§¤í•‘ | âŒ | Track C â€” dart_ í‘œì¤€ ê³„ì • |
| í˜„ê¸ˆíë¦„ ì¡°ì •í•­ëª© | âŒ | Track C â€” dart_/ifrs í‘œì¤€ |
| **entity_ í™•ì¥ ê³„ì •** | âœ… | íšŒì‚¬ ê³ ìœ , lab-ko.xml ë¼ë²¨ë¡œ 1ì°¨ ì‹œë„ í›„ ì‹¤íŒ¨ ì‹œ |
| **TextBlock ë¹„ì •í˜• íŒŒì‹±** | âœ… | ì„œìˆ í˜• ì£¼ì„ ì•ˆ ìˆ«ì ì¶”ì¶œ |
| **cal.xmlì— ì—†ëŠ” ê²€ì¦** | âœ… | ë¹„í‘œì¤€ ê³„ì‚°ê´€ê³„ í™•ì¸ |

**ë¹„ìš© ì‹œë®¬ë ˆì´ì…˜ (íšŒì‚¬ 1ê°œ ê¸°ì¤€):**

```
Track Cë¡œ ì²˜ë¦¬:      ~40ê°œ ì£¼ì„ í•­ëª© â†’ LLM 0ì›
entity_ í•´ì„:        ~5-10íšŒ í˜¸ì¶œ Ã— Gemini Flash Lite(ë¬´ë£Œ) â†’ 0ì›
TextBlock íŒŒì‹±:      ~2-3íšŒ í˜¸ì¶œ Ã— Gemini 2.5 Pro(ë¬´ë£Œ) â†’ 0ì›
ë³µí•© í…Œì´ë¸”:         ~0-1íšŒ í˜¸ì¶œ Ã— Opus 4.6(Antigravity ë¬´ë£Œ) â†’ 0ì›

â†’ ì´ ë¹„ìš©: 0ì› (Google ë¬´ë£Œ + Antigravity OAuth)
â†’ Groq Llama ì‚¬ìš© ì‹œì—ë„ ë¬´ë£Œ (RPD 1,000)
```

| ì „ëµ | ì„¤ëª… | ì ˆê° íš¨ê³¼ |
|------|------|----------|
| **Track C ìš°ì„ ** | XBRLì—ì„œ êµ¬ì¡°+ë¼ë²¨ ë¨¼ì € ì¶”ì¶œ | LLM í˜¸ì¶œ 80%+ ê°ì†Œ |
| **aliases ì‚¬ì „** | ìì£¼ ë‚˜ì˜¤ëŠ” ë³€í˜•ì„ yamlì— ë¯¸ë¦¬ ë“±ë¡ | ë‚˜ë¨¸ì§€ 50~70% ê°ì†Œ |
| **SQLite ìºì‹±** | íšŒì‚¬-ì£¼ì„ìœ í˜•ë³„ ë§¤í•‘ ê²°ê³¼ ì €ì¥ | ê°™ì€ íšŒì‚¬ ë°˜ë³µ ì¡°íšŒ ì‹œ 0ì› |
| **ë¬´ë£Œ ëª¨ë¸ ìš°ì„ ** | Gemini Flash Lite â†’ Groq â†’ Opus ìˆœ | ìœ ë£Œ API 0ì› |
| **ë°°ì¹˜ ì²˜ë¦¬** | ì—¬ëŸ¬ ê³„ì •ëª…ì„ í•œ ë²ˆì— ë§¤í•‘ ìš”ì²­ | API í˜¸ì¶œ íšŸìˆ˜ ìµœì†Œí™” |

---

## 6. ì˜ˆìƒ ë‚œê´€ê³¼ ëŒ€ì‘

> **âš ï¸ SNTë‹¤ì´ë‚´ë¯¹ìŠ¤ XBRL ë¶„ì„ìœ¼ë¡œ ë°œê²¬ëœ í•µì‹¬ ìˆ˜ì •ì‚¬í•­ (2025.02)**
>
> ì‹¤ì œ XBRL íŒŒì¼(`entity00134477_2025-12-31`)ì„ ë¶„ì„í•œ ê²°ê³¼, ê¸°ì¡´ Track B(HTML íŒŒì‹±) ì„¤ê³„ì— ê·¼ë³¸ì  ë³´ì™„ì´ í•„ìš”í•˜ë‹¤. **XBRL ìì²´ê°€ ì£¼ì„ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”í•´ì„œ ê°–ê³  ìˆìœ¼ë©°**, HTML íŒŒì‹±ë³´ë‹¤ í›¨ì”¬ ì •í™•í•œ Track C(XBRL ì§ì ‘ íŒŒì‹±)ë¥¼ ì¶”ê°€í•´ì•¼ í•œë‹¤.

### 6-0. ì‹ ê·œ: Track C â€” XBRL ì£¼ì„ ì§ì ‘ íŒŒì‹±

**ë°œê²¬ ì‚¬ì‹¤: DART XBRLì—ëŠ” ì£¼ì„ ë°ì´í„°ê°€ êµ¬ì¡°í™”ë˜ì–´ ìˆë‹¤**

XBRL zip ì•ˆì˜ 5ê°œ íŒŒì¼ì´ í•˜ëŠ” ì—­í• :

| íŒŒì¼ | ì—­í•  | í™œìš© |
|------|------|------|
| `_pre.xml` | í”„ë ˆì  í…Œì´ì…˜ â€” ì–´ë–¤ ê³„ì •ì´ ì–´ë–¤ ì£¼ì„ì— ì†í•˜ëŠ”ì§€ **roleë³„ êµ¬ì¡°** | ì£¼ì„ í•­ëª© ë¶„ë¥˜ì˜ ì •ë‹µì§€ |
| `_lab-ko.xml` | í•œêµ­ì–´ ë¼ë²¨ â€” account_id â†’ í•œêµ­ì–´ ê³„ì •ëª… ë§¤í•‘ | LLM ì—†ì´ ê³„ì •ëª… í™•ë³´ |
| `_lab-en.xml` | ì˜ì–´ ë¼ë²¨ | ê¸€ë¡œë²Œ ë§¤í•‘ìš© |
| `_cal.xml` | ê³„ì‚° ê´€ê³„ â€” í•©ê³„/êµ¬ì„± ê´€ê³„ | ê³„ì •ê°„ ê´€ê³„ íŒŒì•… |
| `_def.xml` | ì •ì˜ â€” í…Œì´ë¸” ì¶•/êµ¬ì„±ì› ì •ì˜ | ë‹¤ì°¨ì› ë°ì´í„° êµ¬ì¡° |

**í•µì‹¬ ë°œê²¬: role ì½”ë“œê°€ IFRS ì£¼ì„ ë²ˆí˜¸ë¥¼ ë°˜ì˜í•œë‹¤**

SNTë‹¤ì´ë‚´ë¯¹ìŠ¤ì˜ pre.xmlì—ì„œ ë°œê²¬ëœ 75ê°œ role ì¤‘, ì¬ë¬´ëª¨ë¸ë§ì— í•µì‹¬ì ì¸ roleë“¤:

```
[íŒê´€ë¹„ ìƒì„¸]
  D431410 = ì—°ê²° í¬ê´„ì†ìµê³„ì‚°ì„œ (I/S ì „ì²´ + íŒê´€ë¹„ í•©ê³„)
  D431415 = ë³„ë„ í¬ê´„ì†ìµê³„ì‚°ì„œ

[ì£¼ì„ ìƒì„¸ â€” ì—¬ê¸°ê°€ í•µì‹¬]
  ias_16_role-D822100  = ìœ í˜•ìì‚° ë³€ë™ (ì·¨ë“/ì²˜ë¶„/ê°ê°€ìƒê°)     â† ì—°ê²°
  ias_16_role-D822105  = ìœ í˜•ìì‚° ë³€ë™                      â† ë³„ë„
  ias_38_role-D823180  = ë¬´í˜•ìì‚° ë³€ë™
  ias_2_role-D826380   = ì¬ê³ ìì‚° ë‚´ì—­ (ìƒí’ˆ/ì œí’ˆ/ì¬ê³µ/ì›ì¬ë£Œ)
  ias_37_role-D827570  = ì¶©ë‹¹ë¶€ì±„
  ifrs_15_role-D831150 = ìˆ˜ìµ ë¶„í•´ (ì œí’ˆë³„/ì§€ì—­ë³„)            â˜…
  ifrs_16_role-D832610 = ë¦¬ìŠ¤ (ì‚¬ìš©ê¶Œìì‚°/ë¦¬ìŠ¤ë¶€ì±„)
  ias_19_role-D834480  = ì¢…ì—…ì›ê¸‰ì—¬ (ê¸‰ì—¬/í‡´ì§ê¸‰ì—¬/ë³µë¦¬í›„ìƒ)
  ias_12_role-D835110  = ë²•ì¸ì„¸
  ias_33_role-D838000  = ì£¼ë‹¹ì´ìµ
  ias_7_role-D851100   = í˜„ê¸ˆíë¦„ ì¡°ì •í•­ëª© ìƒì„¸                â˜…
  ifrs_8_role-D871100  = ì˜ì—…ë¶€ë¬¸ ì •ë³´                      â˜…
  ias_24_role-D818000  = íŠ¹ìˆ˜ê´€ê³„ì ê±°ë˜

[entity í™•ì¥ (Uë¡œ ì‹œì‘)]
  entity_role-U800300  = íšŒì‚¬ ê³ ìœ  ì£¼ì„ (ê¸°íƒ€)               â† íšŒì‚¬ë§ˆë‹¤ ë‹¤ë¦„
```

**í•µì‹¬ ë°œê²¬: íŒê´€ë¹„ ìƒì„¸ ê³„ì •ì´ DART í™•ì¥(dart_)ìœ¼ë¡œ í‘œì¤€í™”ë˜ì–´ ìˆë‹¤**

HTML íŒŒì‹± ì—†ì´ XBRLì—ì„œ ì§ì ‘ ì¶”ì¶œ ê°€ëŠ¥í•œ íŒê´€ë¹„ ê³„ì •ë“¤:

```
dart_SalariesWages                                          â†’ ê¸‰ì—¬
dart_ProvisionForSeveranceIndemnities                        â†’ í‡´ì§ê¸‰ì—¬
dart_EmployeeBenefits ë˜ëŠ” dart_EmployeeBenefitsSellingGeneralAdministrativeExpenses â†’ ë³µë¦¬í›„ìƒë¹„
dart_DepreciationExpenseSellingGeneralAdministrativeExpenses  â†’ ê°ê°€ìƒê°ë¹„
dart_BadDebtExpensesSellingGeneralAdministrativeExpenses      â†’ ëŒ€ì†ìƒê°ë¹„
dart_CommissionsSellingGeneralAdministrativeExpenses          â†’ ì§€ê¸‰ìˆ˜ìˆ˜ë£Œ
dart_AdvertisingExpensesSellingGeneralAdministrativeExpenses  â†’ ê´‘ê³ ì„ ì „ë¹„
dart_FreightExpensesSellingGeneralAdministrativeExpenses      â†’ ìš´ë°˜ë¹„
dart_TaxesDuesSellingGeneralAdministrativeExpenses            â†’ ì„¸ê¸ˆê³¼ê³µê³¼
dart_TravelExpensesSellingGeneralAdministrativeExpenses       â†’ ì—¬ë¹„êµí†µë¹„
dart_TrainingExpensesSellingGeneralAdministrativeExpenses     â†’ êµìœ¡í›ˆë ¨ë¹„
dart_RentalExpensesSellingGeneralAdministrativeExpenses       â†’ ì„ì°¨ë£Œ
dart_InsurancePremiumsSellingGeneralAdministrativeExpenses    â†’ ë³´í—˜ë£Œ
dart_OrdinaryDevelopmentExpenseSellingGeneralAdministrativeExpenses â†’ ê²½ìƒê°œë°œë¹„
dart_EntertainmentExpensesSellingGeneralAdministrativeExpenses â†’ ì ‘ëŒ€ë¹„
dart_MiscellaneousExpenses                                   â†’ ê¸°íƒ€íŒê´€ë¹„
dart_TotalSellingGeneralAdministrativeExpenses                â†’ íŒê´€ë¹„ í•©ê³„
```

â†’ **ì´ ê³„ì •ë“¤ì€ dart_ ì ‘ë‘ì–´ë¡œ í‘œì¤€í™”ë˜ì–´ ìˆì–´ì„œ, íšŒì‚¬ê°€ ë‹¬ë¼ë„ ë™ì¼í•œ IDë¥¼ ì‚¬ìš©í•œë‹¤.**
â†’ ê¸°ì¡´ ì„¤ê³„ì˜ "íšŒì‚¬ë§ˆë‹¤ ê³„ì •ëª…ì´ ë‹¬ë¼ì„œ LLM ì •ê·œí™”ê°€ í•„ìš”í•˜ë‹¤"ëŠ” ì „ì œê°€ **íŒê´€ë¹„ì— í•œí•´ì„œëŠ”** í‹€ë ¸ë‹¤.

**Track C êµ¬í˜„ â€” `xbrl_parser.py`**

```python
import xml.etree.ElementTree as ET
from pathlib import Path
from dataclasses import dataclass

@dataclass
class XBRLNote:
    role_code: str           # ì˜ˆ: "D831150"
    role_name: str           # ì˜ˆ: "ìˆ˜ìµ ë¶„í•´"
    accounts: list[dict]     # [{account_id, label_ko, label_en, source}]
    members: list[dict]      # ë‹¤ì°¨ì› ì¶• (ë¶€ë¬¸ëª…, ìì‚° ìœ í˜• ë“±)

class XBRLNoteParser:
    """
    XBRL íŒŒì¼ì—ì„œ ì£¼ì„ ë°ì´í„°ë¥¼ ì§ì ‘ íŒŒì‹±.
    
    HTML íŒŒì‹±(Track B)ë³´ë‹¤ ì •í™•í•˜ê³  LLMì´ ë¶ˆí•„ìš”í•œ ê²½ìš°ê°€ ë§ë‹¤.
    ë‹¨, XBRLì—ëŠ” 'êµ¬ì¡°'ë§Œ ìˆê³  'ê°’(ê¸ˆì•¡)'ì€ ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì„œì— ìˆìœ¼ë¯€ë¡œ,
    êµ¬ì¡° + ë¼ë²¨ ì¶”ì¶œì— ì‚¬ìš©í•˜ê³ , ê¸ˆì•¡ì€ fnlttSinglAcntAll API(Track A)
    ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì„œì—ì„œ ê°€ì ¸ì˜¨ë‹¤.
    """

    # ì¬ë¬´ëª¨ë¸ë§ì— í•„ìš”í•œ ì£¼ì„ role ë§¤í•‘
    # role ì½”ë“œ ëìë¦¬: 0 = ì—°ê²°, 5 = ë³„ë„
    #
    # [SKí•˜ì´ë‹‰ìŠ¤ vs SNTë‹¤ì´ë‚´ë¯¹ìŠ¤ ë¹„êµ ê²€ì¦ ì™„ë£Œ]
    # 53ê°œ ê³µí†µ role í™•ì¸. ì•„ë˜ëŠ” í•µì‹¬ roleë§Œ ìˆ˜ë¡.
    # íšŒì‚¬ì— ë”°ë¼ ì¶”ê°€ roleì´ ìˆì„ ìˆ˜ ìˆìŒ (ì˜ˆ: SKëŠ” D834120 ì£¼ì‹ê¸°ì¤€ë³´ìƒ)
    NOTE_ROLES = {
        # â”€â”€ 3ëŒ€ ì¬ë¬´ì œí‘œ (Track Aì™€ ê²¹ì¹˜ì§€ë§Œ, XBRLì—ì„œ ì¶”ê°€ êµ¬ì¡° í™•ì¸ìš©) â”€â”€
        "D210000": "ì¬ë¬´ìƒíƒœí‘œ",         # dart
        "D431410": "í¬ê´„ì†ìµê³„ì‚°ì„œ",       # dart
        "D520000": "í˜„ê¸ˆíë¦„í‘œ",          # dart
        "D610000": "ìë³¸ë³€ë™í‘œ",          # dart

        # â”€â”€ ë¹„ìš© êµ¬ì¡° (í•µì‹¬) â”€â”€
        "D834300": "ë¹„ìš©ì„±ê²©ë³„ë¶„ë¥˜",       # dart â€” ì œì¡°+íŒê´€ë¹„ë¥¼ ì„±ê²©ë³„ í•©ì‚° â˜…
        "D834310": "íŒê´€ë¹„ìƒì„¸",          # dart â€” íŒê´€ë¹„ ì„¸ë¶€ í•­ëª© â˜…
        "D834320": "íŒê´€ë¹„ìƒì„¸2",         # dart â€” ì¼ë¶€ íšŒì‚¬ì—ì„œ ì‚¬ìš©
        "D834330": "íŒê´€ë¹„ìƒì„¸3",         # dart â€” ì¼ë¶€ íšŒì‚¬ì—ì„œ ì‚¬ìš©

        # â”€â”€ ìì‚°/ë¶€ì±„ ìƒì„¸ â”€â”€
        "D822100": "ìœ í˜•ìì‚°",           # ias_16
        "D823180": "ë¬´í˜•ìì‚°",           # ias_38
        "D825100": "íˆ¬ìë¶€ë™ì‚°",          # ias_40
        "D826380": "ì¬ê³ ìì‚°",           # ias_2
        "D827570": "ì¶©ë‹¹ë¶€ì±„",           # ias_37

        # â”€â”€ ê¸ˆìœµìƒí’ˆ â”€â”€
        "D822300": "ê¸ˆìœµìì‚°ìƒì„¸",         # dart
        "D822310": "ê¸ˆìœµë¶€ì±„ìƒì„¸",         # dart
        "D822380": "ê¸ˆìœµìƒí’ˆìœ„í—˜",         # dart/ifrs_7
        "D822390": "ê¸ˆìœµìì‚°ë²”ì£¼",         # ifrs_7
        "D822400": "ì°¨ì…ê¸ˆìƒì„¸",          # ifrs_7 â€” SKí•˜ì´ë‹‰ìŠ¤ì—ì„œ ë°œê²¬
        "D822420": "ê³µì •ê°€ì¹˜ì¸¡ì •",         # ifrs_7
        "D822430": "ê³µì •ê°€ì¹˜ì„œì—´",         # ifrs_7
        "D822470": "ì‚¬ìš©ì œí•œê¸ˆìœµìì‚°",      # ifrs_7 â€” SKí•˜ì´ë‹‰ìŠ¤ì—ì„œ ë°œê²¬
        "D822490": "ê¸°íƒ€ì§€ê¸‰ì±„ë¬´",         # ifrs_7 â€” SKí•˜ì´ë‹‰ìŠ¤ì—ì„œ ë°œê²¬

        # â”€â”€ ìˆ˜ìµ/ë¶€ë¬¸ â”€â”€
        "D831150": "ìˆ˜ìµë¶„í•´",           # ifrs_15 â˜…
        "D871100": "ì˜ì—…ë¶€ë¬¸",           # ifrs_8  â˜…

        # â”€â”€ ê¸°íƒ€ ì£¼ì„ â”€â”€
        "D832610": "ë¦¬ìŠ¤",             # ifrs_16
        "D834120": "ì£¼ì‹ê¸°ì¤€ë³´ìƒ",         # ifrs_2 â€” SKí•˜ì´ë‹‰ìŠ¤ì—ì„œ ë°œê²¬
        "D834480": "ì¢…ì—…ì›ê¸‰ì—¬",          # ias_19
        "D835110": "ë²•ì¸ì„¸",            # ias_12
        "D838000": "ì£¼ë‹¹ì´ìµ",           # ias_33
        "D818000": "íŠ¹ìˆ˜ê´€ê³„ì",          # ias_24
        "D851100": "í˜„ê¸ˆíë¦„ì¡°ì •",         # ias_7  â˜…
        "D861200": "ìë³¸ìƒì„¸",           # ias_1
        "D861300": "ì´ìµì‰ì—¬ê¸ˆ",          # ias_1
    }

    def __init__(self, xbrl_dir: str):
        """XBRL zip í•´ì œ í›„ ë””ë ‰í† ë¦¬ ê²½ë¡œ"""
        self.dir = Path(xbrl_dir)
        self.labels_ko = {}   # account_id â†’ í•œêµ­ì–´ ë¼ë²¨
        self.labels_en = {}   # account_id â†’ ì˜ì–´ ë¼ë²¨

    def parse(self) -> list[XBRLNote]:
        """ì „ì²´ íŒŒì‹± ì‹¤í–‰"""
        # 1. ë¼ë²¨ ë¡œë“œ
        self._load_labels()

        # 2. pre.xmlì—ì„œ roleë³„ ê³„ì • êµ¬ì¡° ì¶”ì¶œ
        notes = self._parse_presentation()

        return notes

    def _load_labels(self):
        """lab-ko.xml, lab-en.xmlì—ì„œ account_id â†’ ë¼ë²¨ ë§¤í•‘ êµ¬ì¶•"""
        ns_xlink = "http://www.w3.org/1999/xlink"

        for lang, attr in [("ko", self.labels_ko), ("en", self.labels_en)]:
            lab_file = list(self.dir.glob(f"*_lab-{lang}.xml"))
            if not lab_file:
                continue

            tree = ET.parse(lab_file[0])
            root = tree.getroot()

            # loc â†’ label ë§¤í•‘ êµ¬ì¶•
            current_account = None
            for elem in root.iter():
                tag = elem.tag.split("}")[-1] if "}" in elem.tag else elem.tag

                if tag == "loc":
                    href = elem.get(f"{{{ns_xlink}}}href", "")
                    if "#" in href:
                        current_account = href.split("#")[-1]

                if tag == "label" and current_account:
                    role = elem.get(f"{{{ns_xlink}}}role", "")
                    # ê¸°ë³¸ ë¼ë²¨ë§Œ (terseLabel, verboseLabel ë“± ì œì™¸)
                    if role == "http://www.xbrl.org/2003/role/label":
                        text = (elem.text or "").strip()
                        if text and current_account not in attr:
                            attr[current_account] = text

        print(f"  ğŸ“ ë¼ë²¨ ë¡œë“œ: KO={len(self.labels_ko)}ê°œ, EN={len(self.labels_en)}ê°œ")

    def _parse_presentation(self) -> list[XBRLNote]:
        """pre.xmlì—ì„œ roleë³„ ê³„ì • êµ¬ì¡° ì¶”ì¶œ"""
        ns = {
            "link": "http://www.xbrl.org/2003/linkbase",
            "xlink": "http://www.w3.org/1999/xlink",
        }

        pre_file = list(self.dir.glob("*_pre.xml"))
        if not pre_file:
            return []

        tree = ET.parse(pre_file[0])
        root = tree.getroot()

        notes = []
        for plink in root.findall(".//link:presentationLink", ns):
            role_uri = plink.get(f'{{{ns["xlink"]}}}role', "")
            role_code = role_uri.split("role-")[-1] if "role-" in role_uri else ""

            # í™€ìˆ˜ ì½”ë“œ = ì—°ê²°, ì§ìˆ˜+5 = ë³„ë„. ì—°ê²°ë§Œ ê¸°ë³¸ íŒŒì‹±
            base_code = role_code.rstrip("5") if role_code.endswith("5") else role_code
            if base_code not in self.NOTE_ROLES:
                continue
            if role_code.endswith("5"):  # ë³„ë„ ì¬ë¬´ì œí‘œëŠ” ìŠ¤í‚µ (ì˜µì…˜)
                continue

            role_name = self.NOTE_ROLES[base_code]

            # loc íƒœê·¸ì—ì„œ ê³„ì • ì¶”ì¶œ
            accounts = []
            members = []
            for loc in plink.findall("link:loc", ns):
                href = loc.get(f'{{{ns["xlink"]}}}href', "")
                if "#" not in href:
                    continue
                account_id = href.split("#")[-1]

                # ì†ŒìŠ¤ êµ¬ë¶„
                if "entity" in href:
                    source = "company"
                elif "dart_" in href:
                    source = "dart"
                else:
                    source = "ifrs"

                # MemberëŠ” ë³„ë„ ë¶„ë¥˜ (ë‹¤ì°¨ì› ì¶•)
                if "Member" in account_id:
                    members.append({
                        "account_id": account_id,
                        "label_ko": self.labels_ko.get(account_id, ""),
                        "source": source,
                    })
                # Abstract, Table, LineItemsëŠ” êµ¬ì¡°ìš©ì´ë¯€ë¡œ ìŠ¤í‚µ
                elif any(kw in account_id for kw in ["Abstract", "Table", "LineItems", "Axis"]):
                    continue
                else:
                    accounts.append({
                        "account_id": account_id,
                        "label_ko": self.labels_ko.get(account_id, ""),
                        "label_en": self.labels_en.get(account_id, ""),
                        "source": source,
                    })

            notes.append(XBRLNote(
                role_code=role_code,
                role_name=role_name,
                accounts=accounts,
                members=members,
            ))

        return notes

    def get_sga_accounts(self) -> dict[str, str]:
        """
        íŒê´€ë¹„ ìƒì„¸ ê³„ì • ì¶”ì¶œ (dart_ í‘œì¤€ ê³„ì •).
        
        LLM ì •ê·œí™” ë¶ˆí•„ìš” â€” dart_ ì ‘ë‘ì–´ ê³„ì •ì€ íšŒì‚¬ê°€ ë‹¬ë¼ë„ ë™ì¼.
        Returns: {account_id: í•œêµ­ì–´ ë¼ë²¨}
        """
        sga_prefix = "dart_"
        sga_suffix_keywords = [
            "SellingGeneralAdministrativeExpenses",
            "SalariesWages",
            "ProvisionForSeveranceIndemnities",
            "EmployeeBenefits",
            "MiscellaneousExpenses",
            "TotalSellingGeneralAdministrativeExpenses",
        ]

        result = {}
        for acc_id, label in self.labels_ko.items():
            if not acc_id.startswith(sga_prefix):
                continue
            if any(kw in acc_id for kw in sga_suffix_keywords) or "íŒê´€ë¹„" in label:
                result[acc_id] = label

        return result

    def get_segment_members(self) -> list[dict]:
        """ì˜ì—…ë¶€ë¬¸ Member ì¶”ì¶œ (íšŒì‚¬ë³„ ê³ ìœ  ë¶€ë¬¸ëª…)"""
        notes = self.parse()
        for note in notes:
            if note.role_name == "ì˜ì—…ë¶€ë¬¸":
                return [m for m in note.members if m["source"] == "company"]
        return []
```

**Track A + C ì¡°í•©ìœ¼ë¡œ LLM ë¶ˆí•„ìš”í•œ ê²½ìš°ê°€ ëŒ€í­ ì¦ê°€**

```
ë³€ê²½ ì „ (Track A + Track B):
  Track A(API)  â†’ B/S, I/S, C/F ê°’
  Track B(HTML) â†’ ì£¼ì„ ìƒì„¸ (LLM ì •ê·œí™” í•„ìˆ˜)

ë³€ê²½ í›„ (Track A + Track C + Track B fallback):
  Track A(API)   â†’ B/S, I/S, C/F ê°’
  Track C(XBRL)  â†’ ì£¼ì„ êµ¬ì¡° + ê³„ì •ID + í•œêµ­ì–´ ë¼ë²¨ (LLM ë¶ˆí•„ìš”)
  Track B(HTML)  â†’ Track Cì—ì„œ ëª» ì¡ëŠ” ì˜ˆì™¸ ì¼€ì´ìŠ¤ë§Œ (fallback)
```

**Track Cë¡œ LLM ì—†ì´ ì²˜ë¦¬ ê°€ëŠ¥í•œ í•­ëª©:**
- íŒê´€ë¹„ ìƒì„¸ (dart_ í‘œì¤€ ê³„ì •)
- ìœ í˜•ìì‚°/ë¬´í˜•ìì‚° ë³€ë™
- ì¬ê³ ìì‚° ë‚´ì—­
- í˜„ê¸ˆíë¦„ ì¡°ì •í•­ëª©
- ì¢…ì—…ì›ê¸‰ì—¬ ë‚´ì—­
- ì£¼ë‹¹ì´ìµ

**ì—¬ì „íˆ Track B(HTML + LLM)ê°€ í•„ìš”í•œ í•­ëª©:**
- íšŒì‚¬ ê³ ìœ  í™•ì¥ ê³„ì •(entity_)ì˜ í•´ì„
- TextBlock(ì„œìˆ í˜• ì£¼ì„)ì— í¬í•¨ëœ ë¹„ì •í˜• ë°ì´í„°
- XBRLì— íƒœê¹…ë˜ì§€ ì•Šì€ ì£¼ì„ ë‚´ìš©

### 6-0-1. SKí•˜ì´ë‹‰ìŠ¤ XBRL ë¹„êµ ë¶„ì„ìœ¼ë¡œ ë°œê²¬ëœ ì¶”ê°€ ì‚¬í•­

> **âš ï¸ SKí•˜ì´ë‹‰ìŠ¤(entity00164779) vs SNTë‹¤ì´ë‚´ë¯¹ìŠ¤(entity00134477) ë¹„êµ (2025.02)**

**1. role ì„¸íŠ¸ê°€ íšŒì‚¬ë§ˆë‹¤ ë‹¤ë¥´ë‹¤ â€” ë™ì  íŒŒì‹± í•„ìˆ˜**

ë‘ íšŒì‚¬ì˜ pre.xmlì„ ë¹„êµí•˜ë©´:
- ê³µí†µ role: 53ê°œ (í•µì‹¬ ì¬ë¬´ì œí‘œ + ì£¼ìš” ì£¼ì„)
- SKì—ë§Œ ìˆëŠ” role: 15ê°œ (ì£¼ì‹ê¸°ì¤€ë³´ìƒ D834120, ì°¨ì…ê¸ˆìƒì„¸ D822400, ì‚¬ìš©ì œí•œìì‚° D822470 ë“±)
- SNTì—ë§Œ ìˆëŠ” role: 16ê°œ (íˆ¬ìë¶€ë™ì‚° D825100, ê¸°íƒ€í¬ê´„ì†ìµ D861000 ë“±)

â†’ **NOTE_ROLESë¥¼ í•˜ë“œì½”ë”©í•˜ë˜, pre.xmlì— ì¡´ì¬í•˜ëŠ” roleë§Œ ë™ì ìœ¼ë¡œ íŒŒì‹±í•´ì•¼ í•œë‹¤.**
â†’ `U800xxx` (entity ê³ ìœ  role)ì€ íšŒì‚¬ë§ˆë‹¤ ê°œìˆ˜ì™€ ë‚´ìš©ì´ ì™„ì „íˆ ë‹¤ë¦„.

**2. íŒê´€ë¹„ dart_ ê³„ì •ì€ í‘œì¤€ì´ì§€ë§Œ, ì‚¬ìš© ì„¸íŠ¸ê°€ ë‹¤ë¥´ë‹¤**

| êµ¬ë¶„ | SKí•˜ì´ë‹‰ìŠ¤ | SNTë‹¤ì´ë‚´ë¯¹ìŠ¤ |
|------|:---:|:---:|
| ê³µí†µ íŒê´€ë¹„ ê³„ì • | 8ê°œ | 8ê°œ |
| SKì—ë§Œ ìˆëŠ” í•­ëª© | ë¬´í˜•ìì‚°ìƒê°ë¹„, íŒë§¤ì´‰ì§„ë¹„ | â€” |
| SNTì—ë§Œ ìˆëŠ” í•­ëª© | â€” | A/Së¹„ìš©, í†µì‹ ë¹„, ë³´ìƒë¹„, ì „ì‚°ë¹„, ìš´ë°˜ë¹„ ë“± 16ê°œ |
| **ì´ íŒê´€ë¹„ ê³„ì •** | **10ê°œ** | **26ê°œ** |

â†’ dart_ ê³„ì • IDëŠ” í‘œì¤€ì´ë¼ ë§¤í•‘ ìì²´ëŠ” LLM ë¶ˆí•„ìš”. ë‹¨, **íšŒì‚¬ë³„ë¡œ ì“°ëŠ” í•­ëª© ì„¸íŠ¸ê°€ ë‹¤ë¥´ë¯€ë¡œ í…œí”Œë¦¿ì— ëª¨ë“  ê°€ëŠ¥í•œ í•­ëª©ì„ ë¯¸ë¦¬ ë‚˜ì—´í•˜ê³ , ë°ì´í„° ìˆëŠ” ê²ƒë§Œ ì±„ìš°ëŠ” ë°©ì‹**ì´ í•„ìš”.

**3. SKí•˜ì´ë‹‰ìŠ¤ì—ì„œ ë°œê²¬ëœ D834300 (ë¹„ìš©ì˜ ì„±ê²©ë³„ ë¶„ë¥˜) â€” ëŒ€í˜• ì œì¡°ì—… í•µì‹¬**

SNTì—ëŠ” ì—†ê³  SKì—ë§Œ ìˆëŠ” role. ì œì¡°ì›ê°€+íŒê´€ë¹„ë¥¼ ì„±ê²©ë³„ë¡œ í•©ì‚°í•œ ë°ì´í„°:

```
ifrs-full_ExpenseByNature (ë¹„ìš©ì˜ ì„±ê²©ë³„ ë¶„ë¥˜ í•©ê³„)
  + ifrs-full_ChangesInInventoriesOfFinishedGoodsAndWorkInProgress (ì¬ê³µí’ˆ ë³€ë™)
  + ifrs-full_RawMaterialsAndConsumablesUsed    (ì›ì¬ë£Œ ì‚¬ìš©)
  + ifrs-full_EmployeeBenefitsExpense           (ì¢…ì—…ì›ê¸‰ì—¬)
  + ifrs-full_DepreciationAndAmortisationExpense (ê°ê°€ìƒê°ë¹„)
  + dart_Commissions                            (ì§€ê¸‰ìˆ˜ìˆ˜ë£Œ)
  + dart_UtilityExpenses                        (ìˆ˜ë„ê´‘ì—´ë¹„)
  + dart_RepairExpenses                         (ìˆ˜ì„ ë¹„)
  + dart_OutsourcingExpenses                    (ì™¸ì£¼ìš©ì—­ë¹„)
  + ifrs-full_OtherExpenseByNature              (ê¸°íƒ€ë¹„ìš©)
```

â†’ ë°˜ë„ì²´ì²˜ëŸ¼ ì œì¡°ì›ê°€ê°€ í•µì‹¬ì¸ ê¸°ì—… ë¶„ì„ì— í•„ìˆ˜. D834310(íŒê´€ë¹„ ìƒì„¸)ì™€ ë³„ê°œë¡œ í™•ë³´í•´ì•¼ í•¨.

**4. í˜„ê¸ˆíë¦„ ì¡°ì •í•­ëª© â€” ê³µí†µ ì½”ì–´ + íšŒì‚¬ë³„ í™•ì¥**

```
ê³µí†µ ì½”ì–´ (13ê°œ) â€” ì–´ëŠ íšŒì‚¬ë“  ë°˜ë“œì‹œ ìˆìŒ:
  ê°ê°€ìƒê°ë¹„, ë¬´í˜•ìì‚°ìƒê°ë¹„, í‡´ì§ê¸‰ì—¬, ë²•ì¸ì„¸ë¹„ìš©,
  ì´ììˆ˜ìµ, ì™¸í™˜ì°¨ì†/ì°¨ìµ, ìœ í˜•ìì‚°ì²˜ë¶„ì†ìµ,
  ë§¤ì¶œì±„ê¶Œ/ì¬ê³ /ë§¤ì…ì±„ë¬´ ë³€ë™, í‡´ì§ê¸ˆ ì§€ê¸‰ ë“±

SK ì „ìš© (15ê°œ): ì†ìƒì°¨ì†/í™˜ì…, ê¸ˆìœµìì‚°ì²˜ë¶„, íŒŒìƒìƒí’ˆ ë“±
SNT ì „ìš© (28ê°œ): íˆ¬ìë¶€ë™ì‚°ê°ê°€, ì‚¬ìš©ê¶Œìì‚°ê°ê°€, ì¶©ë‹¹ë¶€ì±„ ë³€ë™ ë“±
```

â†’ **í˜„ê¸ˆíë¦„ ì¡°ì •ì€ "ê³µí†µ ì½”ì–´ + íšŒì‚¬ë³„ ê°€ë³€ í•­ëª©" êµ¬ì¡°ë¡œ ì„¤ê³„í•´ì•¼ í•œë‹¤.**

**5. cal.xml = ìë™ ê²€ì¦ì˜ ì •ë‹µì§€**

cal.xmlì˜ ê³„ì‚°ê´€ê³„ëŠ” `weight` ì†ì„±ìœ¼ë¡œ ë¶€í˜¸ë¥¼ ì •í™•íˆ ì§€ì •:

```python
# I/S ê³„ì‚° ì²´ì¸ ì˜ˆì‹œ (SKí•˜ì´ë‹‰ìŠ¤ D431410):
GrossProfit        = + Revenue - CostOfSales
OperatingIncome    = + GrossProfit - TotalSGA
ProfitBeforeTax    = + OperatingIncome + FinanceIncome - FinanceCosts
                     + OtherGains - OtherLosses + ShareOfAssociates
ProfitLoss         = + ProfitBeforeTax - IncomeTaxExpense
ComprehensiveIncome = + ProfitLoss + OCI
```

ì´ë¥¼ í™œìš©í•œ ìë™ ê²€ì¦ ëª¨ë“ˆ:

```python
class CalValidation:
    """
    cal.xmlì˜ ê³„ì‚°ê´€ê³„ë¥¼ ì´ìš©í•œ ìë™ ê²€ì¦.
    
    Track Aì—ì„œ ê°€ì ¸ì˜¨ ê¸ˆì•¡ì´ cal.xmlì˜ ìˆ˜ì‹ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸.
    ë¶ˆì¼ì¹˜ ì‹œ ê²½ê³  ì¶œë ¥ â†’ ë°ì´í„° ì˜¤ë¥˜ ë˜ëŠ” API ì‘ë‹µ ëˆ„ë½ íƒì§€.
    """

    def __init__(self, cal_file: str):
        self.relations = self._parse_cal(cal_file)

    def _parse_cal(self, cal_file: str) -> dict[str, list[tuple[str, str, float]]]:
        """
        cal.xml íŒŒì‹± â†’ {role_code: [(parent, child, weight), ...]}
        """
        tree = ET.parse(cal_file)
        root = tree.getroot()
        ns = {
            "link": "http://www.xbrl.org/2003/linkbase",
            "xlink": "http://www.w3.org/1999/xlink",
        }

        result = {}
        for clink in root.findall(".//link:calculationLink", ns):
            role = clink.get(f'{{{ns["xlink"]}}}role', "")
            role_code = role.split("role-")[-1] if "role-" in role else ""

            # loc ë§¤í•‘
            loc_map = {}
            for loc in clink.findall("link:loc", ns):
                label = loc.get(f'{{{ns["xlink"]}}}label', "")
                href = loc.get(f'{{{ns["xlink"]}}}href', "")
                if "#" in href:
                    loc_map[label] = href.split("#")[-1]

            # arcì—ì„œ ê³„ì‚°ê´€ê³„ ì¶”ì¶œ
            rels = []
            for arc in clink.findall("link:calculationArc", ns):
                from_l = arc.get(f'{{{ns["xlink"]}}}from', "")
                to_l = arc.get(f'{{{ns["xlink"]}}}to', "")
                weight = float(arc.get("weight", "1"))

                parent = loc_map.get(from_l, "")
                child = loc_map.get(to_l, "")
                if parent and child:
                    rels.append((parent, child, weight))

            if rels:
                result[role_code] = rels

        return result

    def validate(
        self,
        role_code: str,
        values: dict[str, float],  # {account_id: ê¸ˆì•¡}
        tolerance: float = 1.0,     # í—ˆìš© ì˜¤ì°¨ (ë‹¨ìœ„: ë°±ë§Œì›)
    ) -> list[dict]:
        """
        ê³„ì‚°ê´€ê³„ ê²€ì¦. ë¶ˆì¼ì¹˜ í•­ëª© ë°˜í™˜.

        ì˜ˆ: B/S(D210000)ì—ì„œ Assets = CurrentAssets + NoncurrentAssets ê²€ì¦
        """
        if role_code not in self.relations:
            return []

        errors = []

        # parentë³„ë¡œ children ê·¸ë£¹í•‘
        from collections import defaultdict
        parent_children = defaultdict(list)
        for parent, child, weight in self.relations[role_code]:
            parent_children[parent].append((child, weight))

        for parent, children in parent_children.items():
            if parent not in values:
                continue

            # ìì‹ í•©ê³„ ê³„ì‚°
            calc_sum = sum(
                values.get(child, 0) * weight
                for child, weight in children
            )
            actual = values[parent]

            diff = abs(actual - calc_sum)
            if diff > tolerance:
                errors.append({
                    "parent": parent,
                    "expected": calc_sum,
                    "actual": actual,
                    "diff": diff,
                    "children": [
                        (c, w, values.get(c, 0)) for c, w in children
                    ],
                })

        return errors
```

**ì‚¬ìš© ì˜ˆì‹œ:**

```python
validator = CalValidation("data/xbrl/entity00164779_cal.xml")

# Track Aì—ì„œ ê°€ì ¸ì˜¨ ê°’
bs_values = {
    "ifrs-full_Assets": 100_000_000,
    "ifrs-full_CurrentAssets": 40_000_000,
    "ifrs-full_NoncurrentAssets": 60_000_000,
    # ...
}

errors = validator.validate("D210000", bs_values)
if errors:
    for e in errors:
        print(f"âš ï¸ {e['parent']}: ê³„ì‚°ê°’={e['expected']:,.0f} vs ì‹¤ì œ={e['actual']:,.0f}")
else:
    print("âœ… B/S ê³„ì‚°ê´€ê³„ ê²€ì¦ í†µê³¼")
```

**6. def.xml = ë‹¤ì°¨ì› í…Œì´ë¸” êµ¬ì¡°ì˜ ì •ë‹µì§€**

def.xmlì€ ì£¼ì„ í…Œì´ë¸”ì˜ ì¶•(Axis)ê³¼ êµ¬ì„±ì›(Member) ê´€ê³„ë¥¼ ì •ì˜:

```
[SKí•˜ì´ë‹‰ìŠ¤ ìˆ˜ìµë¶„í•´ D831150]

í…Œì´ë¸” 1: ì œí’ˆë³„ ë§¤ì¶œ
  ì¶•: SegmentsAxis
    â”œâ”€â”€ DRAM          (entity í™•ì¥)
    â”œâ”€â”€ NAND Flash    (entity í™•ì¥)
    â””â”€â”€ ê¸°íƒ€           (entity í™•ì¥)
  ê°’: Revenue

í…Œì´ë¸” 2: ì§€ì—­ë³„ ë§¤ì¶œ
  ì¶•: GeographicalAreasAxis
    â”œâ”€â”€ êµ­ë‚´           (CountryOfDomicileMember, IFRS í‘œì¤€)
    â””â”€â”€ í•´ì™¸           (ForeignCountriesMember)
         â”œâ”€â”€ ë¯¸êµ­      (dart_USMember, DART í‘œì¤€)
         â”œâ”€â”€ ì¤‘êµ­      (dart_CNMember, DART í‘œì¤€)
         â”œâ”€â”€ ì•„ì‹œì•„ê¸°íƒ€  (entity í™•ì¥)
         â””â”€â”€ ìœ ëŸ½      (entity í™•ì¥)
  ê°’: Revenue

í…Œì´ë¸” 3: ì´í–‰ì‹œì ë³„ ë§¤ì¶œ
  ì¶•: PerformanceObligationsAxis
    â”œâ”€â”€ í•œ ì‹œì ì— ì´í–‰  (IFRS í‘œì¤€)
    â””â”€â”€ ê¸°ê°„ì— ê±¸ì³ ì´í–‰ (IFRS í‘œì¤€)
  ê°’: Revenue
```

â†’ **def.xmlì„ íŒŒì‹±í•˜ë©´ HTML í…Œì´ë¸” íŒŒì‹± ì—†ì´ë„ ì£¼ì„ í…Œì´ë¸”ì˜ í–‰/ì—´ êµ¬ì¡°ë¥¼ ì •í™•íˆ ì•Œ ìˆ˜ ìˆë‹¤.**
â†’ ë‹¨, def.xmlì—ëŠ” 'êµ¬ì¡°'ë§Œ ìˆê³  'ê°’(ê¸ˆì•¡)'ì€ ì—†ìœ¼ë¯€ë¡œ, ì¸ìŠ¤í„´ìŠ¤ ë¬¸ì„œ(.xbrl)ë‚˜ APIì—ì„œ ê°’ì„ ê°€ì ¸ì™€ì•¼ í•¨.

```python
class XBRLDefParser:
    """def.xmlì—ì„œ í…Œì´ë¸”ì˜ ë‹¤ì°¨ì› êµ¬ì¡°ë¥¼ ì¶”ì¶œ"""

    def parse_table_structure(
        self, def_file: str, role_code: str,
    ) -> dict:
        """
        íŠ¹ì • roleì˜ í…Œì´ë¸” êµ¬ì¡° ì¶”ì¶œ.
        
        Returns:
            {
                "axes": [
                    {"axis_id": "SegmentsAxis", "members": [
                        {"id": "DramMember", "label": "DRAM", "source": "company"},
                        ...
                    ]},
                ],
                "line_items": ["Revenue", "OperatingIncomeLoss", ...],
            }
        """
        tree = ET.parse(def_file)
        root = tree.getroot()
        ns = {
            "link": "http://www.xbrl.org/2003/linkbase",
            "xlink": "http://www.w3.org/1999/xlink",
        }

        for dlink in root.findall(".//link:definitionLink", ns):
            role = dlink.get(f'{{{ns["xlink"]}}}role', "")
            if role_code not in role:
                continue

            loc_map = {}
            for loc in dlink.findall("link:loc", ns):
                label = loc.get(f'{{{ns["xlink"]}}}label', "")
                href = loc.get(f'{{{ns["xlink"]}}}href', "")
                if "#" in href:
                    loc_map[label] = href.split("#")[-1]

            # dimension â†’ member ê´€ê³„ ì¶”ì¶œ
            axes = {}
            line_items = []

            for arc in dlink.findall("link:definitionArc", ns):
                arcrole = arc.get(f'{{{ns["xlink"]}}}arcrole', "")
                from_acc = loc_map.get(arc.get(f'{{{ns["xlink"]}}}from', ""), "")
                to_acc = loc_map.get(arc.get(f'{{{ns["xlink"]}}}to', ""), "")

                rel = arcrole.split("/")[-1]

                if rel == "domain-member" and "Member" in to_acc:
                    # ì–´ëŠ ì¶•ì˜ memberì¸ì§€ ì°¾ê¸°
                    if from_acc.endswith("Member") or from_acc.endswith("Domain"):
                        # parent memberì— ì¶”ê°€
                        for axis_id, axis_data in axes.items():
                            if from_acc in [m["id"] for m in axis_data] or from_acc == axis_data[0].get("domain"):
                                axes[axis_id].append({"id": to_acc})

                if rel == "hypercube-dimension" and "Axis" in to_acc:
                    axes[to_acc] = []

                if rel == "dimension-domain":
                    if to_acc in axes:
                        pass  # domain ì„¤ì •
                    for axis_id in axes:
                        if from_acc == axis_id:
                            axes[axis_id] = [{"domain": to_acc}]

            return {"axes": axes, "line_items": line_items}

        return {}
```

### 6-0-2. íšŒì‚¬ê°„ ë¹„êµì—ì„œ ë„ì¶œëœ ì„¤ê³„ ì›ì¹™

| ì›ì¹™ | ê·¼ê±° |
|------|------|
| **roleì€ ë™ì  íƒìƒ‰** | SK 68ê°œ vs SNT 69ê°œ, 15~16ê°œ ì°¨ì´ |
| **dart_ ê³„ì •ì€ ì‹ ë¢°í•˜ë˜, ì„¸íŠ¸ëŠ” ê°€ë³€** | íŒê´€ë¹„: SK 10ê°œ vs SNT 26ê°œ |
| **entity_ ê³„ì •ì€ í•­ìƒ LLM ë˜ëŠ” label ì°¸ì¡°** | SK 1,144ê°œ vs SNT 716ê°œ, ì™„ì „íˆ ë‹¤ë¦„ |
| **cal.xmlì€ ê²€ì¦ì—, def.xmlì€ í…Œì´ë¸” êµ¬ì¡°ì—** | ê°’ì´ ì•„ë‹Œ êµ¬ì¡°/ê´€ê³„ ì •ë³´ |
| **D834300 ë¹„ìš©ì„±ê²©ë³„ë¶„ë¥˜ëŠ” ì œì¡°ì—… í•„ìˆ˜** | SKì—ë§Œ ìˆìŒ, ì›ê°€êµ¬ì¡° ë¶„ì„ í•µì‹¬ |
| **í˜„ê¸ˆíë¦„ì€ ì½”ì–´13 + ê°€ë³€** | ê³µí†µ ì¡°ì •í•­ëª© ìœ„ì£¼ë¡œ í…œí”Œë¦¿ ì„¤ê³„ |

### 6-1. Track A: ë¶„ê¸° ë³´ê³ ì„œì˜ ëˆ„ì /ë¶„ê¸° ê¸ˆì•¡ í˜¼ì¬

ë°˜ê¸°Â·ë¶„ê¸° ë³´ê³ ì„œì˜ I/S, C/FëŠ” ëˆ„ì  ê¸ˆì•¡(`thstrm_amount`)ê³¼ í•´ë‹¹ ë¶„ê¸° ê¸ˆì•¡(`thstrm_add_amount`)ì´ ë¶„ë¦¬ëœë‹¤. ì—°ê°„ ëª¨ë¸ì´ ì•„ë‹Œ ë¶„ê¸° ëª¨ë¸ì„ ë§Œë“¤ ë•Œ ì£¼ì˜ê°€ í•„ìš”í•˜ë‹¤.

```
ëŒ€ì‘: report_codeë³„ë¡œ ëˆ„ì  vs ë¶„ê¸° ê¸ˆì•¡ì„ êµ¬ë¶„í•˜ëŠ” ë¡œì§
â†’ ì‚¬ì—…ë³´ê³ ì„œ(11011)ëŠ” ì—°ê°„ì´ë¼ ë¬¸ì œ ì—†ìŒ
â†’ ë¶„ê¸° ë³´ê³ ì„œëŠ” ì „ë¶„ê¸° ëˆ„ì ì„ ë¹¼ì„œ í•´ë‹¹ ë¶„ê¸° ê¸ˆì•¡ ì‚°ì¶œ
```

### 6-2. Track A: íšŒì‚¬ë³„ ì¶”ê°€ ê³„ì •

í‘œì¤€ taxonomy ì™¸ì— íšŒì‚¬ê°€ ìì²´ ì¶”ê°€í•œ ê³„ì •(`dart_xxx`)ì´ ìˆì„ ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ `dart_OperatingIncomeLoss`(ì˜ì—…ì´ìµ)ëŠ” K-IFRS í‘œì¤€ì´ ì•„ë‹Œ í•œêµ­ DART í™•ì¥ ê³„ì •ì´ë‹¤.

```
ëŒ€ì‘: í…œí”Œë¦¿ì— ì£¼ìš” dart_ í™•ì¥ ê³„ì •ë„ ë¯¸ë¦¬ í¬í•¨
â†’ ifrs-full_ + dart_ ê³„ì •ì„ ëª¨ë‘ ì»¤ë²„
```

### 6-3. Track B: í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨

ì¼ë¶€ íšŒì‚¬ëŠ” ì£¼ì„ì„ í‘œ ëŒ€ì‹  ì„œìˆ í˜•ìœ¼ë¡œ ì‘ì„±í•œë‹¤.

```
ëŒ€ì‘: LLMì—ê²Œ ì›ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì£¼ê³  êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ ìš”ì²­
â†’ "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ íŒê´€ë¹„ í•­ëª©ë³„ ê¸ˆì•¡ì„ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜"
```

### 6-4. Track B: ë³‘í•©ì…€/ë‹¤ì¤‘ í—¤ë”

DART HTML í…Œì´ë¸”ì€ `colspan`, `rowspan`ì´ ë³µì¡í•˜ê²Œ ì‚¬ìš©ëœë‹¤.

```
ëŒ€ì‘: pd.read_html() ì‹¤íŒ¨ ì‹œ BeautifulSoupìœ¼ë¡œ ì§ì ‘ íŒŒì‹±í•˜ëŠ” fallback ë¡œì§
â†’ ì…€ ë‹¨ìœ„ë¡œ ìˆœíšŒí•˜ë©° ë³‘í•© ë²”ìœ„ë¥¼ ì¶”ì 
```

### 6-5. ì—°ê²°/ë³„ë„ ì¬ë¬´ì œí‘œ êµ¬ë¶„

ê°™ì€ ê³µì‹œ ì•ˆì— ì—°ê²°ì¬ë¬´ì œí‘œì™€ ë³„ë„ì¬ë¬´ì œí‘œê°€ ëª¨ë‘ í¬í•¨ëœë‹¤.

```
ëŒ€ì‘: HTML ë³¸ë¬¸ì—ì„œ "ì—°ê²°" í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ ì„¹ì…˜ ë¶„ë¦¬
â†’ ê¸°ë³¸ê°’ì€ ì—°ê²°ì¬ë¬´ì œí‘œ ìš°ì„ 
```

### 6-6. Track B: ë‹¨ìœ„ ë¶ˆì¼ì¹˜

ì–´ë–¤ íšŒì‚¬ëŠ” ë°±ë§Œì›, ì–´ë–¤ íšŒì‚¬ëŠ” ì› ë‹¨ìœ„ë¡œ ê¸°ì¬í•œë‹¤.

```
ëŒ€ì‘: í…Œì´ë¸” ìƒë‹¨/í•˜ë‹¨ì˜ "(ë‹¨ìœ„: ë°±ë§Œì›)" ê°™ì€ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ë‹¨ìœ„ ìŠ¹ìˆ˜ ì ìš©
```

---

## 7. í™•ì¥ ë¡œë“œë§µ

**Phase 1 â€” MVP (í˜„ì¬)**
- ë‹¨ì¼ íšŒì‚¬, 3ëŒ€ ì¬ë¬´ì œí‘œ(Track A) + íŒê´€ë¹„/ë¶€ë¬¸ë³„ë§¤ì¶œ 2ê°œ ì£¼ì„(Track B)
- ìˆ˜ë™ìœ¼ë¡œ corp_code ì…ë ¥
- 3ê°œë…„ ì‹œê³„ì—´

**Phase 2 â€” ë©€í‹°ì»´í¼ë‹ˆ**
- ì—¬ëŸ¬ íšŒì‚¬ë¥¼ batchë¡œ ì²˜ë¦¬
- ìºì‹œ íˆíŠ¸ìœ¨ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

**Phase 3 â€” ì‹œê³„ì—´ ìë™í™”**
- ìµœê·¼ 3~5ë…„ì¹˜ ìë™ ìˆ˜ì§‘
- ì „ê¸°/ë‹¹ê¸° ë¹„êµ ê²€ì¦ ë¡œì§ (ìˆ«ì ë¶ˆì¼ì¹˜ ê²½ê³ )

**Phase 4 â€” í’€ ì¬ë¬´ëª¨ë¸ ì—°ë™**
- DCF, ë©€í‹°í”Œ ë°¸ë¥˜ì—ì´ì…˜ ì‹œíŠ¸ ìë™ ì—…ë°ì´íŠ¸
- ì£¼ì„ ë°ì´í„° â†’ ê°€ì •(assumption) ì‹œíŠ¸ ìë™ ë°˜ì˜

---

## 8. í•„ìš” íŒ¨í‚¤ì§€

```txt
# requirements.txt
requests>=2.31.0
beautifulsoup4>=4.12.0
lxml>=4.9.0
pandas>=2.0.0
openpyxl>=3.1.0
pyyaml>=6.0
openai>=1.0.0        # ë˜ëŠ” anthropic SDK
```
